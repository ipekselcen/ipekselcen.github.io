<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ipekselcen.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ipekselcen.github.io/" rel="alternate" type="text/html"/><updated>2026-01-17T22:07:05+00:00</updated><id>https://ipekselcen.github.io/feed.xml</id><title type="html">blank</title><subtitle>Recent PhD graduate in Biochemistry specializing in epigenetics, chromatin biology, and multi-omics analysis. Bridging wet lab expertise with computational approaches. </subtitle><entry><title type="html"></title><link href="https://ipekselcen.github.io/blog/2026/2026-01-17-bisulfite/" rel="alternate" type="text/html" title=""/><published>2026-01-17T22:07:05+00:00</published><updated>2026-01-17T22:07:05+00:00</updated><id>https://ipekselcen.github.io/blog/2026/2026-01-17-bisulfite</id><content type="html" xml:base="https://ipekselcen.github.io/blog/2026/2026-01-17-bisulfite/"><![CDATA[<h2 id="the-problem-that-changed-everything">The Problem That Changed Everything</h2> <p>In 1992, Marianne Frommer faced what seemed like a simple question: how do you tell the difference between a methylated cytosine and an unmethylated one? Both are cytosines. Both look identical under a microscope. Both have the same mass on a spectrometer.</p> <p>Her solution—treating DNA with sodium bisulfite to chemically convert unmethylated cytosines to uracils while leaving methylated cytosines untouched—became bisulfite sequencing, the gold standard for measuring DNA methylation. But here’s what’s fascinating: this experimental innovation forced biologists to start thinking computationally, whether they realized it or not.</p> <p>Why? Because bisulfite sequencing doesn’t give you a direct readout of methylation. It gives you sequences full of Ts (converted from unmethylated Cs) and Cs (originally methylated). Someone—or something—has to <strong>infer</strong> the original methylation state by comparing treated to untreated DNA.</p> <div class="alert alert-info" role="alert"> <p><strong>Key Insight:</strong> That inference step? That’s computational thinking. The moment you have to reconstruct information from transformed data, you’re already doing computation—even if you’re just using Excel.</p> </div> <hr/> <h2 id="decomposition-breaking-down-the-methylation-problem">Decomposition: Breaking Down the Methylation Problem</h2> <p>Let’s unpack what bisulfite sequencing actually requires you to do. This is where computational thinking starts: with <strong>decomposition</strong>—breaking a complex problem into manageable pieces.</p> <p><strong>The experimental question:</strong> “What is the methylation status of my genomic region?”</p> <p><strong>The computational breakdown:</strong></p> <ol> <li>Align bisulfite-converted reads to a reference genome (but the reads don’t match perfectly anymore)</li> <li>Identify which Cs became Ts (unmethylated sites)</li> <li>Identify which Cs stayed Cs (methylated sites)</li> <li>Calculate methylation percentage per site</li> <li>Account for incomplete conversion (some Cs don’t convert even if unmethylated)</li> <li>Account for sequencing errors (some Ts might be sequencing mistakes, not conversions)</li> </ol> <p>Each of these is its own computational problem. And here’s the kicker: in the early days, biologists did steps 2-6 by hand, often using Excel. They were doing computational thinking without formal training.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bisulfite_workflow-480.webp 480w,/assets/img/bisulfite_workflow-800.webp 800w,/assets/img/bisulfite_workflow-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/bisulfite_workflow.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Bisulfite sequencing workflow showing experimental and computational steps</figcaption> </figure> </div> </div> <div class="caption"> Note: Replace with actual workflow diagram </div> <h3 id="the-pattern-recognition-emerges">The Pattern Recognition Emerges</h3> <p>By the mid-2000s, researchers realized they were solving the same alignment problem over and over. Different labs were writing similar scripts. The community needed a standardized tool.</p> <p>Enter <strong>Bismark</strong> (2011), which automated the entire pipeline. But Bismark didn’t just automate existing manual steps—it introduced <strong>abstraction</strong>: the tool could handle single-end or paired-end reads, different reference genomes, various quality filters. One algorithm, many applications.</p> <hr/> <h2 id="pattern-recognition-the-chromatin-accessibility-revolution">Pattern Recognition: The Chromatin Accessibility Revolution</h2> <p>Fast forward to 2013. Jason Buenrostro at Stanford develops ATAC-seq (Assay for Transposase-Accessible Chromatin using sequencing). Instead of asking “where is DNA methylated?”, he asks “where is chromatin accessible?”</p> <p>The experimental approach is elegantly simple: a hyperactive transposase (Tn5) cuts DNA at accessible regions and simultaneously inserts sequencing adapters. Sequence the fragments, and you have a map of open chromatin.</p> <p>But here’s where <strong>pattern recognition</strong> becomes crucial. ATAC-seq doesn’t just give you a list of open regions. It gives you:</p> <ul> <li>Read depth (how accessible is each region?)</li> <li>Fragment length distribution (are nucleosomes present?)</li> <li>Footprints (protected regions within accessible chromatin where transcription factors bind)</li> </ul> <div class="alert alert-success" role="alert"> <p><strong>Pattern Recognition in Action:</strong> Early ATAC-seq papers just counted peaks. Then researchers noticed patterns: certain genomic regions showed stereotypical fragment length distributions. A peak with many ~40-50bp fragments suggested nucleosome-free regions. Longer fragments (~200bp) indicated mononucleosomes.</p> </div> <p>By 2016, tools like <strong>NucleoATAC</strong> were extracting nucleosome positioning and transcription factor occupancy from the same ATAC-seq data, because the patterns were there all along—they just needed algorithms to recognize them systematically.</p> <p>The key insight: ATAC-seq fragment lengths aren’t noise. They’re data. But recognizing that required thinking computationally about what the experimental readout was actually telling you.</p> <hr/> <h2 id="algorithmic-thinking-chip-seq-and-the-peak-calling-problem">Algorithmic Thinking: ChIP-seq and the Peak Calling Problem</h2> <p>Chromatin immunoprecipitation followed by sequencing (ChIP-seq) gives you a pile of DNA fragments representing where your protein of interest was bound. Your challenge: where, exactly, were the binding sites?</p> <p>This is an <strong>algorithmic thinking</strong> problem: given noisy data with background signal, how do you systematically identify true binding events?</p> <div class="row"> <div class="col-sm-6 mt-3 mt-md-0"> <div class="card"> <div class="card-body"> <h5 class="card-title text-danger">❌ Naive Algorithm</h5> <ol> <li>Align reads to genome</li> <li>Count reads in sliding windows</li> <li>Call regions with high counts as "peaks"</li> <li>Done</li> </ol> <p class="card-text"><small class="text-muted">What early researchers did manually</small></p> </div> </div> </div> <div class="col-sm-6 mt-3 mt-md-0"> <div class="card border-success"> <div class="card-body"> <h5 class="card-title text-success">✓ Sophisticated Algorithm (MACS2)</h5> <ol> <li>Model local background using control samples</li> <li>Shift reads to estimate fragment centers</li> <li>Use dynamic lambda (local background rate)</li> <li>Calculate fold enrichment and statistical significance</li> <li>Call peaks using FDR cutoff</li> <li>Report peak summits, not just regions</li> </ol> </div> </div> </div> </div> <p>Notice the difference? The sophisticated algorithm doesn’t just count. It <strong>models</strong> the data generation process (how reads are created from fragments, how background varies locally) and uses that model to make better inferences.</p> <div class="alert alert-warning" role="alert"> <p><strong>This is algorithmic thinking:</strong> Designing a step-by-step procedure that accounts for the structure of your problem.</p> </div> <hr/> <h2 id="abstraction-single-cell-multi-omics">Abstraction: Single-Cell Multi-Omics</h2> <p>Here’s where epigenetics methods get really interesting computationally. By 2018, we had:</p> <ul> <li>scATAC-seq: single-cell chromatin accessibility</li> <li>scRNA-seq: single-cell gene expression</li> <li>Single-cell bisulfite sequencing: single-cell methylation</li> </ul> <p>Each generates sparse, noisy data. Each requires different computational approaches. But researchers started asking: what if we measured multiple epigenetic layers in the <strong>same</strong> cells?</p> <h3 id="the-multi-omics-explosion-2020-2025">The Multi-Omics Explosion (2020-2025)</h3> <pre><code class="language-mermaid">timeline
    title Evolution of Multi-Omics Methods
    2020 : SHARE-seq : Simultaneous RNA + chromatin accessibility
    2021 : 10x Multiome : Commercial platform for paired RNA + ATAC
    2025 : Spatial-Mux-seq : Chromatin + histones + protein + RNA in spatial context
</code></pre> <p>The computational challenge: these assays measure fundamentally different things. RNA-seq counts molecules. ATAC-seq measures accessibility. Methylation is binary at each CG site.</p> <p><strong>Abstraction to the rescue:</strong> Tools like <strong>Signac</strong> and <strong>ArchR</strong> introduced a unified framework.</p> <div class="card mb-3 border-primary"> <div class="card-header bg-primary text-white"> <strong>The Key Abstraction</strong> </div> <div class="card-body"> <p>All single-cell data can be represented as:</p> <ul> <li><strong>Cell × Feature matrix</strong> (what you measure)</li> <li><strong>Metadata</strong> (cell annotations, quality metrics)</li> <li><strong>Dimensional reduction</strong> (shared latent space)</li> </ul> <p>Whether you have RNA counts, ATAC peaks, or methylation rates, this framework applies. The computational operations—normalization, feature selection, clustering, visualization—work on the abstract representation, not the raw data type.</p> </div> </div> <p>This is abstraction: identifying common structure across different domains and building tools that work at that level of generality.</p> <hr/> <h2 id="the-deep-learning-revolution-when-pattern-recognition-meets-abstraction">The Deep Learning Revolution: When Pattern Recognition Meets Abstraction</h2> <h3 id="2024-the-year-foundation-models-arrived-in-epigenetics">2024: The Year Foundation Models Arrived in Epigenetics</h3> <p>Taskiran et al. (Nature, 2024) trained a deep learning model on single-cell ATAC-seq to learn enhancer grammar. Not “where are enhancers?” but “what makes an enhancer work?”</p> <p>The model learned to:</p> <ul> <li>Design synthetic enhancers from scratch</li> <li>Predict cell-type specificity from sequence alone</li> <li>Generate minimal 50bp sequences that still function as enhancers</li> </ul> <p>Meanwhile, Bravo González-Blas et al. (Nature Cell Biology, 2024) developed <strong>DeepLiver</strong>, which predicts how enhancer architecture encodes spatial identity in the liver. Single-nucleotide resolution. Experimentally validated.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepliver_architecture-480.webp 480w,/assets/img/deepliver_architecture-800.webp 800w,/assets/img/deepliver_architecture-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/deepliver_architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> DeepLiver hierarchical model architecture: from accessibility prediction to activity and zonation </div> <h3 id="whats-computationally-different-about-foundation-models">What’s Computationally Different About Foundation Models?</h3> <table class="table table-sm"> <thead> <tr> <th>Traditional Approaches</th> <th>Foundation Model Approaches</th> </tr> </thead> <tbody> <tr> <td>1. Design experiment<br/>2. Collect data<br/>3. Apply statistics<br/>4. Interpret results</td> <td>1. Train on millions of cells<br/>2. Learn generalizable patterns<br/>3. Generate predictions<br/>4. Test predictions experimentally<br/>5. Refine model</td> </tr> </tbody> </table> <p>The model becomes the hypothesis generator. It discovers patterns humans wouldn’t have designed experiments to test.</p> <h3 id="but-heres-the-critical-lesson-from-2025">But Here’s the Critical Lesson from 2025</h3> <div class="alert alert-danger" role="alert"> <p><strong>⚠️ Critical Computational Thinking:</strong> Just because it’s deep learning doesn’t mean it’s better.</p> <p>Ahlmann-Eltze et al. (Nature Methods, 2025) showed that foundation models for predicting gene perturbation responses didn’t outperform simple baselines. The hype around AI in genomics needed rigorous benchmarking.</p> </div> <p>This is <strong>algorithmic evaluation</strong>: don’t just build fancy models. Ask:</p> <ul> <li>What is the simplest approach that would work?</li> <li>How much better is your complex method?</li> <li>Is the added complexity worth it?</li> </ul> <hr/> <h2 id="what-biologists-can-learn-from-this-history">What Biologists Can Learn From This History</h2> <p>Every methods advance in epigenetics required computational thinking, even if the developers didn’t call it that:</p> <table> <thead> <tr> <th>Method</th> <th>Computational Thinking Skill</th> </tr> </thead> <tbody> <tr> <td><strong>Bisulfite sequencing (1992)</strong></td> <td>Decomposition—breaking experimental readouts into inference steps</td> </tr> <tr> <td><strong>ATAC-seq (2013)</strong></td> <td>Pattern recognition—seeing signal in fragment length distributions</td> </tr> <tr> <td><strong>ChIP-seq peak calling</strong></td> <td>Algorithmic thinking—designing procedures that account for data structure</td> </tr> <tr> <td><strong>Multi-omics (2020s)</strong></td> <td>Abstraction—finding common frameworks across data types</td> </tr> <tr> <td><strong>Foundation models (2024-2025)</strong></td> <td>Critical evaluation—distinguishing transformative tools from hype</td> </tr> </tbody> </table> <hr/> <h2 id="practical-exercise-think-through-a-methods-paper-computationally">Practical Exercise: Think Through a Methods Paper Computationally</h2> <p>Next time you read a methods paper, ask yourself these questions:</p> <details><summary>Click to expand: Computational Thinking Framework</summary> <p><strong>Decomposition:</strong></p> <ul> <li>What is the experimental readout, and what biological question does it answer?</li> <li>What are the steps from raw data to biological conclusion?</li> <li>Which steps are experimental? Which are computational?</li> </ul> <p><strong>Pattern recognition:</strong></p> <ul> <li>What patterns in the data indicate signal vs. noise?</li> <li>Are there unexpected patterns the authors exploit (like ATAC-seq fragment lengths)?</li> <li>What assumptions about data structure does the analysis make?</li> </ul> <p><strong>Algorithmic thinking:</strong></p> <ul> <li>What is the step-by-step procedure for going from reads to results?</li> <li>How does the algorithm handle edge cases (low coverage, ambiguous mappings, batch effects)?</li> <li>Could you describe the algorithm to someone else and they’d get the same results?</li> </ul> <p><strong>Abstraction:</strong></p> <ul> <li>Does this method generalize beyond the specific application shown?</li> <li>What is the minimal necessary input? What is optional?</li> <li>Could the core approach be adapted to other biological questions?</li> </ul> <p><strong>Evaluation:</strong></p> <ul> <li>How is this method benchmarked against alternatives?</li> <li>What are the failure modes? When would a simpler approach work just as well?</li> <li>Are the computational claims rigorously tested?</li> </ul> </details> <hr/> <h2 id="the-computational-thinking-you-already-have">The Computational Thinking You Already Have</h2> <p>If you’ve ever:</p> <ul> <li>✓ Troubleshot why your Western blot didn’t work (<strong>decomposition</strong>)</li> <li>✓ Noticed that your ChIP peaks always appear near TSSs (<strong>pattern recognition</strong>)</li> <li>✓ Written a step-by-step protocol (<strong>algorithmic thinking</strong>)</li> <li>✓ Designed a cloning strategy that works for multiple constructs (<strong>abstraction</strong>)</li> <li>✓ Tested whether you really need that expensive antibody (<strong>evaluation</strong>)</li> </ul> <p>…then you’re already thinking computationally.</p> <div class="alert alert-success" role="alert"> <p><strong>The transition to computational biology isn’t learning to think differently.</strong> It’s learning to apply the problem-solving skills you already have to questions where the “experiment” is running code instead of pipetting samples.</p> </div> <hr/> <h2 id="looking-forward-programmable-biology">Looking Forward: Programmable Biology</h2> <p>The most exciting methods papers in 2025 share a common thread: they’re moving from <em>describing</em> biology to <em>programming</em> it.</p> <div class="card-deck"> <div class="card"> <div class="card-body"> <h5 class="card-title">PERT</h5> <h6 class="card-subtitle mb-2 text-muted">Pierce et al., Nature, 2025</h6> <p class="card-text">Prime editing that reads through stop codons, potentially treating dozens of genetic diseases with a single construct</p> </div> </div> <div class="card"> <div class="card-body"> <h5 class="card-title">Perturb-FISH</h5> <h6 class="card-subtitle mb-2 text-muted">Binan et al., Cell, 2025</h6> <p class="card-text">CRISPR screening with spatial transcriptomics, capturing cell-autonomous and intercellular effects simultaneously</p> </div> </div> <div class="card"> <div class="card-body"> <h5 class="card-title">Base editing screens</h5> <h6 class="card-subtitle mb-2 text-muted">Multiple labs, 2024-2025</h6> <p class="card-text">Connecting GWAS variants to functional outcomes at scale</p> </div> </div> </div> <p><br/></p> <p>These methods require sophisticated computational thinking at every step:</p> <ul> <li>Designing guide RNAs (<strong>algorithmic design</strong>)</li> <li>Analyzing spatial genetic interactions (<strong>multi-dimensional pattern recognition</strong>)</li> <li>Linking variants to phenotypes (<strong>causal inference in high-dimensional space</strong>)</li> </ul> <p>The wet lab and the computational lab aren’t separate anymore. Every experiment generates data that requires algorithmic interpretation. Every analysis makes assumptions about biology that should be experimentally validated.</p> <hr/> <h2 id="epilogue-the-biologists-advantage">Epilogue: The Biologist’s Advantage</h2> <p>The biologists who thrive in this environment won’t necessarily be the ones who learn to code (though that helps). They’ll be the ones who learn to think about biological problems the way Marianne Frommer thought about bisulfite sequencing: <strong>as an inference problem where experimental design and computational analysis are inseparable.</strong></p> <div class="alert alert-info" role="alert"> <p><strong>Remember:</strong> When Frommer developed bisulfite sequencing in 1992, she wasn’t trying to teach anyone computational thinking. She was just trying to measure methylation. But in solving that problem, she inadvertently created a method that would force an entire generation of biologists to think computationally.</p> <p>That’s the beautiful irony: the best computational methods emerge not from trying to be computational, but from trying to answer biological questions well.</p> </div> <hr/> <h2 id="references--further-reading">References &amp; Further Reading</h2> <p><strong>Historical methods:</strong></p> <ul> <li>Frommer et al. (1992). “A genomic sequencing protocol that yields a positive display of 5-methylcytosine residues in individual DNA strands.” <em>PNAS</em> 89(5):1827-1831.</li> <li>Buenrostro et al. (2013). “Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position.” <em>Nature Methods</em> 10:1213–1218.</li> </ul> <p><strong>Computational tools:</strong></p> <ul> <li>Krueger &amp; Andrews (2011). “Bismark: a flexible aligner and methylation caller for Bisulfite-Seq applications.” <em>Bioinformatics</em> 27(11):1571-1572.</li> <li>Zhang et al. (2008). “Model-based analysis of ChIP-Seq (MACS).” <em>Genome Biology</em> 9:R137.</li> <li>Schep et al. (2017). “chromVAR: inferring transcription-factor-associated accessibility from single-cell epigenomic data.” <em>Nature Methods</em> 14:975–978.</li> </ul> <p><strong>Modern multi-omics:</strong></p> <ul> <li>Ma et al. (2020). “Chromatin Potential Identified by Shared Single-Cell Profiling of RNA and Chromatin.” <em>Cell</em> 183(4):1103-1116.</li> <li>Guo et al. (2025). “Spatial-Mux-seq: versatile spatial multiplexing of multi-omics modalities.” <em>Nature Methods</em> 22:520–529.</li> </ul> <p><strong>Foundation models &amp; critical evaluation:</strong></p> <ul> <li>Taskiran, I.I. et al. (2024). “Cell-type-directed design of synthetic enhancers.” <em>Nature</em> 626:212–220.</li> <li>Bravo González-Blas, C. et al. (2024). “Single-cell spatial multi-omics and deep learning dissect enhancer-driven gene regulatory networks in liver zonation.” <em>Nature Cell Biology</em> 26(1):153-167.</li> <li>Ahlmann-Eltze, C. et al. (2025). “Comparison of transformers and simple baselines for predicting perturbation responses.” <em>Nature Methods</em> 22:1657–1661.</li> </ul> <p><strong>Programmable biology:</strong></p> <ul> <li>Pierce, S.E. et al. (2025). “Prime editing-installed suppressor tRNAs for disease-agnostic genome editing.” <em>Nature</em> 648:191–202.</li> <li>Binan, L. et al. (2025). “Simultaneous CRISPR screening and spatial transcriptomics reveal intracellular, intercellular, and functional transcriptional circuits.” <em>Cell</em> 188(8):2141-2158.</li> </ul> <hr/> <p><em>This post is part of an ongoing series on computational thinking for experimental biologists.</em></p>]]></content><author><name></name></author></entry><entry><title type="html">What I Wish Someone Had Told Me About TET1: A Computational Thinking Journey</title><link href="https://ipekselcen.github.io/blog/2026/tet1-computational-thinking/" rel="alternate" type="text/html" title="What I Wish Someone Had Told Me About TET1: A Computational Thinking Journey"/><published>2026-01-02T00:00:00+00:00</published><updated>2026-01-02T00:00:00+00:00</updated><id>https://ipekselcen.github.io/blog/2026/tet1-computational-thinking</id><content type="html" xml:base="https://ipekselcen.github.io/blog/2026/tet1-computational-thinking/"><![CDATA[<p>I spent the first two years of my PhD memorizing pathways. “TET1 oxidizes 5-methylcytosine.” Check. “5hmC is an intermediate in demethylation.” Check. “TET enzymes regulate gene expression.” Check.</p> <p>Then I knocked out TET2 in my oligodendrocyte progenitor cells, ran RNA-seq, and… nothing made sense.</p> <p>The patterns I saw didn’t match any textbook. My PI was confused. I was confused. I’d generated beautiful data but had no framework to interpret it. That’s when I realized: <strong>I’d been memorizing recipes without understanding the logic</strong>.</p> <p>This post is what I wish someone had told me in year one. Not as a computational expert - I’m still learning - but as someone who finally started asking different questions.</p> <h2 id="the-problem-with-how-we-learn-biology">The Problem With How We Learn Biology</h2> <p>Here’s how I was taught DNA methylation:</p> <blockquote class="block-warning"> <p><strong>The Clean Story</strong></p> <ul> <li>DNA gets methylated (5mC) → Gene silenced</li> <li>DNA loses methylation → Gene active</li> <li>TET enzymes reverse methylation</li> <li>Therefore: TET knockout = more methylation = more silencing</li> </ul> </blockquote> <p>This made perfect sense in lectures. It completely failed in my experiments.</p> <p><strong>Why?</strong> Because biology isn’t a linear pathway. It’s a network with:</p> <ul> <li><strong>Redundancy</strong> (TET1, TET2, AND TET3 - why three?)</li> <li><strong>Compensation</strong> (lose one, others adapt)</li> <li><strong>Context-dependence</strong> (same enzyme, different outcomes in different cells)</li> <li><strong>Multi-layer regulation</strong> (not just DNA methylation - chromatin, RNA modifications, metabolic state)</li> </ul> <p>Nobody told me this. I had to learn it by banging my head against confusing data for months.</p> <h2 id="the-turning-point-tet1-discovery">The Turning Point: TET1 Discovery</h2> <p>In 2009, TET1 was discovered.<sup>1</sup> The textbook version goes:</p> <p>“TET1 oxidizes 5-methylcytosine, providing a mechanism for active DNA demethylation.”</p> <p><strong>What I missed</strong> (and what took me years to appreciate): This wasn’t just finding a new enzyme. It was revealing that <strong>DNA methylation is a state space, not a binary switch</strong>.</p> <h3 id="what-that-actually-means">What That Actually Means</h3> <p>Instead of:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Methylated (OFF) ⟷ Unmethylated (ON)
</code></pre></div></div> <p>We have:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>C → 5mC → 5hmC → 5fC → 5caC → C
</code></pre></div></div> <p><strong>Why does this matter?</strong> Because each state:</p> <ul> <li>Has different protein readers</li> <li>Exists at different stability levels</li> <li>Serves different regulatory functions</li> <li>Creates different biological outcomes</li> </ul> <p>This means the cell can encode way more information than just “on” or “off.” It can create states like:</p> <ul> <li>“Poised” (ready to activate quickly)</li> <li>“Active but dynamic” (fluctuating)</li> <li>“Progressively shutting down” (transitioning)</li> <li>“Stably repressed” (locked)</li> </ul> <blockquote class="block-tip"> <p><strong>What Clicked For Me</strong></p> <p>When I first learned about 5hmC, I thought: “Oh, an intermediate. Cool.”</p> <p>What I should have thought: “Wait - if 5hmC accumulates to 1% of all cytosines in ESCs, it’s NOT just an intermediate. It’s serving a function. The cell is CHOOSING to keep DNA in this intermediate state.”</p> <p>That shift - from thinking about intermediates to thinking about <strong>states the cell maintains</strong> - changed everything.</p> </blockquote> <h2 id="my-tet2-confusion-and-what-it-taught-me">My TET2 Confusion (And What It Taught Me)</h2> <p>Let me tell you about my actual data, because this is where linear thinking completely broke down.</p> <p><strong>My prediction (linear thinking):</strong></p> <ul> <li>TET2 knockout → less 5hmC → more stable 5mC → genes stay repressed</li> </ul> <p><strong>What I actually saw:</strong></p> <ul> <li>TET2 knockout → some 5hmC decrease BUT</li> <li>TET1 and TET3 expression increased (compensation)</li> <li>RNA modifications changed (unexpected)</li> <li>Chromatin accessibility shifted at unexpected sites</li> <li>Gene expression changes didn’t correlate simply with 5hmC loss</li> </ul> <p><strong>My PI’s reaction:</strong> “This is messy. Maybe technical variation?”</p> <p><strong>What was actually happening:</strong> The cell was adapting. Network compensation. Multi-layer regulation. <strong>Exactly what you’d predict if you thought computationally</strong>, but I didn’t have that framework yet.</p> <h2 id="what-thinking-computationally-actually-means">What “Thinking Computationally” Actually Means</h2> <p>I used to think “computational biology” meant “learning Python and running pipelines.”</p> <p>That’s not it.</p> <p><strong>Computational thinking means asking:</strong></p> <ol> <li><strong>What’s the state space?</strong> (Not just “on/off” - what are ALL possible states?)</li> <li><strong>What are the network connections?</strong> (Who compensates when something breaks?)</li> <li><strong>What are the multi-layer regulations?</strong> (DNA methylation doesn’t act alone)</li> <li><strong>What’s the cell optimizing for?</strong> (Stability vs. flexibility? Speed vs. accuracy?)</li> </ol> <p>Let me show you what this looks like in practice.</p> <h3 id="question-1-why-three-tet-enzymes">Question 1: Why Three TET Enzymes?</h3> <p><strong>Linear thinking:</strong> “Evolution is messy. Probably redundant.”</p> <p><strong>Computational thinking:</strong> “Redundancy in biology usually means something. Let me think about this as a network.”</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This is how I started thinking about it
# (Warning: I'm still learning Python, this is conceptual)
</span>
<span class="n">network</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">TET1</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">targets</span><span class="sh">'</span><span class="p">:</span> <span class="n">gene_set</span><span class="p">,</span> <span class="sh">'</span><span class="s">expression</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">constitutive</span><span class="sh">'</span><span class="p">},</span>
    <span class="sh">'</span><span class="s">TET2</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">targets</span><span class="sh">'</span><span class="p">:</span> <span class="n">gene_set</span><span class="p">,</span> <span class="sh">'</span><span class="s">expression</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">inducible</span><span class="sh">'</span><span class="p">},</span>  
    <span class="sh">'</span><span class="s">TET3</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">targets</span><span class="sh">'</span><span class="p">:</span> <span class="n">gene_set</span><span class="p">,</span> <span class="sh">'</span><span class="s">expression</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">tissue_specific</span><span class="sh">'</span><span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Question: If I knock out TET2, what happens?
# Linear: TET2 targets lose 5hmC
# Network: Do TET1/3 compensate? Do cells reroute regulation?
</span></code></pre></div></div> <p>When I finally looked at published TET1 knockout data,<sup>4</sup> mice were <strong>viable and fertile</strong>. Subtle defects, but mostly fine.</p> <p><strong>Why?</strong> Network compensation. TET2 and TET3 picked up the slack.</p> <p><strong>What this taught me:</strong> When you see three enzymes doing similar things, don’t think “redundant waste.” Think “robust system with failsafes.”</p> <p>The cell isn’t stupid. We’re just not asking the right questions.</p> <h3 id="question-2-is-5hmc-transient-or-stable">Question 2: Is 5hmC Transient or Stable?</h3> <p>This is where computational thinking saved me from misinterpreting my own data.</p> <p><strong>What I measured:</strong> 5hmC at certain promoters in my OPCs.</p> <p><strong>Linear interpretation:</strong> “5hmC is present, so demethylation is happening here.”</p> <p><strong>Computational question:</strong> “Wait - if 5hmC is just a transient intermediate, why is it so abundant in ESCs (1% of all cytosines)?”<sup>3</sup></p> <p>Let me think about kinetics:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># If 5hmC is transient:</span><span class="w">
</span><span class="c1"># k1 (5mC → 5hmC) ≈ k2 (5hmC → 5fC)</span><span class="w">
</span><span class="c1"># Steady state: [5hmC] should be very low</span><span class="w">

</span><span class="c1"># If 5hmC is stable:</span><span class="w">
</span><span class="c1"># k1 (5mC → 5hmC) &gt;&gt; k2 (5hmC → 5fC)  </span><span class="w">
</span><span class="c1"># Steady state: [5hmC] accumulates</span><span class="w">

</span><span class="c1"># The data shows: 5hmC is ABUNDANT</span><span class="w">
</span><span class="c1"># Therefore: k2 must be slow</span><span class="w">
</span><span class="c1"># Meaning: 5hmC is not just passing through</span><span class="w">
</span></code></pre></div></div> <p><strong>What this means:</strong> 5hmC isn’t just “on the way to demethylation.” It’s a <strong>mark the cell maintains</strong> to keep genes in a poised state.</p> <p><strong>Why this matters for my research:</strong> When I see 5hmC at a promoter in my OPCs, it might not mean “actively demethylating.” It might mean “maintaining plasticity” - ready to go either way depending on signals.</p> <p>Completely different biological interpretation. Same data.</p> <blockquote class="block-warning"> <p><strong>The Struggle Is Real</strong></p> <p>I didn’t figure this out quickly. I spent MONTHS confused about my 5hmC data. I kept thinking “is my hMeRIP-seq bad?” when really, I was asking the wrong questions.</p> <p>The turning point was reading papers about 5hmC in development and realizing: <strong>the cell uses 5hmC to maintain flexible states</strong>. It’s not a bug, it’s a feature.</p> </blockquote> <h2 id="the-multi-layer-reality-nobody-tells-you">The Multi-Layer Reality Nobody Tells You</h2> <p>Here’s what really frustrated me: <strong>Every paper I read would focus on ONE layer of regulation</strong> and claim causality.</p> <p>“TET2 mutation causes reduced 5hmC, leading to gene X downregulation.”</p> <p>But when I looked at my data, I had to ask:</p> <ul> <li>Did chromatin accessibility change? (Yes)</li> <li>Did RNA modifications change? (Yes, unexpectedly)</li> <li>Did metabolic state shift? (Probably)</li> <li>Did other TET enzymes compensate? (Definitely)</li> <li>Were there feedback loops I’m missing? (Almost certainly)</li> </ul> <p><strong>The reality:</strong> DNA methylation is ONE layer in a multi-layer regulatory system.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cell State
    ↓
Metabolic State → ATP levels → Chromatin Remodeling
    ↓                              ↓
Transcription Factors → Chromatin Accessibility
    ↓                              ↓
DNA Methylation (5mC/5hmC) ← RNA Modifications
    ↓                              ↓
Histone Modifications → Gene Expression
    ↓
Feedback Loops
</code></pre></div></div> <p><strong>When you perturb ONE thing</strong> (like knocking out TET2), the <strong>entire system responds</strong>. You’re not seeing “the effect of TET2” - you’re seeing the <strong>system’s adaptation to losing TET2</strong>.</p> <p>This is why:</p> <ul> <li>My RNA-seq alone didn’t tell the story</li> <li>I needed ATAC-seq to see chromatin changes</li> <li>I needed hMeRIP-seq to see RNA modification responses</li> <li>I needed metabolic profiling to understand the cellular state</li> <li>I STILL don’t have the complete picture</li> </ul> <h2 id="what-i-do-differently-now">What I Do Differently Now</h2> <p>I’m not going to pretend I have this figured out. I’m still learning. But here’s what changed in how I approach my research:</p> <h3 id="before-running-experiments">Before Running Experiments</h3> <p><strong>Old me:</strong> “I’ll knock out TET2 and do RNA-seq.”</p> <p><strong>Current me:</strong></p> <ol> <li>Draw the network on paper. Where are backup systems?</li> <li>What multi-layer regulations exist?</li> <li>What would linear thinking predict?</li> <li>What would network compensation predict?</li> <li>What additional data would I need to distinguish these?</li> </ol> <p><strong>This doesn’t mean I always do the perfect experiment.</strong> Money and time are real constraints. But at least I <strong>know what I’m missing</strong>.</p> <h3 id="when-analyzing-data">When Analyzing Data</h3> <p><strong>Old me:</strong> Run DESeq2 → Get gene list → Run GO enrichment → Call it a day</p> <p><strong>Current me:</strong></p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># After DESeq2, ask:</span><span class="w">
</span><span class="c1"># 1. Does this pattern match network predictions?</span><span class="w">
</span><span class="c1"># 2. Are compensatory genes changing?</span><span class="w">
</span><span class="c1"># 3. What if I'm measuring adaptation, not direct effects?</span><span class="w">
</span><span class="c1"># 4. What other layers should I check?</span><span class="w">

</span><span class="c1"># Example from my actual analysis:</span><span class="w">
</span><span class="n">results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">DESeq2_results</span><span class="w">
</span><span class="n">up_genes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">filter</span><span class="p">(</span><span class="n">results</span><span class="p">,</span><span class="w"> </span><span class="n">log2FC</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">padj</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w">

</span><span class="c1"># Check: Are TET1/TET3 in my up-regulated genes?</span><span class="w">
</span><span class="c1"># If yes → network compensation, as predicted</span><span class="w">
</span><span class="c1"># If no → something else is going on, investigate</span><span class="w">
</span></code></pre></div></div> <h3 id="when-reading-papers">When Reading Papers</h3> <p><strong>Old me:</strong> Trust the interpretation in the abstract.</p> <p><strong>Current me:</strong></p> <ul> <li>Did they check for compensation?</li> <li>Is this correlation or causation?</li> <li>What layers of regulation did they ignore?</li> <li>Would their conclusions hold if the system adapted?</li> </ul> <p><strong>Example:</strong> I recently read a paper claiming “TET2 loss causes specific gene downregulation.”</p> <p>Red flags:</p> <ul> <li>❌ Didn’t measure TET1/TET3 (compensation?)</li> <li>❌ Didn’t measure chromatin state (accessibility changes?)</li> <li>❌ Endpoint analysis only (what about dynamics?)</li> <li>❌ Assumed direct causality (network effects?)</li> </ul> <p>I’m not saying the paper is wrong. I’m saying <strong>their interpretation assumed linearity</strong> in a clearly non-linear system.</p> <h2 id="the-checklist-i-use-now">The Checklist I Use Now</h2> <p>Before making claims about my data, I ask:</p> <p><strong>□ State Space Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Am I thinking binary when I should think spectrum?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What states can the system occupy?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What transitions are possible?</li> </ul> <p><strong>□ Network Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What compensates if this breaks?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Are there parallel pathways?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What feedback loops exist?</li> </ul> <p><strong>□ Multi-Layer Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What other regulatory layers are involved?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Did I measure them?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>If not, how does that limit my interpretation?</li> </ul> <p><strong>□ Plasticity Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Is the cell adapting to my perturbation?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Am I measuring steady-state or transition?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Would temporal dynamics change my interpretation?</li> </ul> <p><strong>□ Causality Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Am I claiming correlation or causation?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What experiment would actually test causality?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What would change my conclusion?</li> </ul> <blockquote class="block-tip"> <p><strong>Reality Check</strong></p> <p>Do I do all of this perfectly? No.</p> <p>Do I have time and money to measure every layer? No.</p> <p>But at least I <strong>know what I’m not measuring</strong> and can qualify my claims accordingly.</p> <p>That’s the difference.</p> </blockquote> <h2 id="what-im-still-learning">What I’m Still Learning</h2> <p>Let me be honest about where I struggle:</p> <p><strong>1. When to stop adding complexity</strong></p> <p>I can spiral into “but what about…” forever. Sometimes you need to make simplifying assumptions to make progress. I’m still learning where to draw that line.</p> <p><strong>2. Quantitative predictions</strong></p> <p>I can think about networks qualitatively. Making actual quantitative predictions? That’s harder. I’m working on it.</p> <p><strong>3. Integrating all the data</strong></p> <p>I have RNA-seq, ATAC-seq, hMeRIP-seq sitting on my hard drive. Integrating them properly is… a work in progress. The conceptual framework is there. The practical execution is messy.</p> <p><strong>4. Communicating uncertainty</strong></p> <p>In talks, PIs want definitive statements. “TET2 regulates gene X.” But what I actually mean is: “TET2 loss correlates with gene X changes, possibly through network adaptation involving chromatin and RNA modifications, but I haven’t proven causality.”</p> <p>How do you say that in a conference talk without sounding wishy-washy?</p> <p>Still figuring that out.</p> <h2 id="why-this-matters-for-you">Why This Matters For You</h2> <p>If you’re early in your PhD (or considering grad school), <strong>please learn this framework earlier than I did</strong>.</p> <p>Not because it makes research easier - it doesn’t. If anything, it makes you realize how much you DON’T know.</p> <p>But it will save you from:</p> <ul> <li>❌ Making overclaimed conclusions</li> <li>❌ Being confused when knockouts don’t match predictions</li> <li>❌ Missing compensation mechanisms</li> <li>❌ Thinking your “messy” data is bad when it’s actually informative</li> </ul> <p><strong>Biology is not linear.</strong> Cells are plastic, adaptive, multi-layer regulatory systems.</p> <p><strong>The sooner you think that way, the better.</strong></p> <h2 id="whats-next">What’s Next</h2> <p>I’m working on a companion post about chromatin accessibility using the same framework - thinking about it as a probability landscape rather than “open” vs “closed.”</p> <p>I’m also writing up my TET2 work (finally). The compensation mechanisms we found are… not what textbooks would predict. But they make perfect sense when you think computationally.</p> <p>After publication, I’ll write about what we learned and what I still don’t understand.</p> <p>For now, if you’re struggling with confusing epigenetics data, know that:</p> <ol> <li>You’re not alone</li> <li>Your data probably isn’t bad</li> <li>You might just be asking linear questions about a non-linear system</li> </ol> <p>Start thinking about networks, plasticity, and multi-layer regulation. Your confusion might turn into clarity.</p> <p>At least, that’s what happened for me.</p> <blockquote class="block-tip"> <p><strong>Coming Up</strong></p> <ul> <li>“Chromatin Accessibility as Probability: What Your ATAC-seq Really Measures”</li> <li>“The TET2 Story: When Compensation Mechanisms Surprise You” (after publication)</li> <li>“How I Actually Analyze Multi-Omics Data (Messy Reality Edition)”</li> </ul> </blockquote> <hr/> <h3 id="references--further-reading">References &amp; Further Reading</h3> <p><strong>The papers that changed how I think:</strong></p> <ol> <li>Tahiliani M, et al. (2009) “Conversion of 5-methylcytosine to 5-hydroxymethylcytosine in mammalian DNA by MLL partner TET1.” <em>Science</em> 324(5929):930-5. <ul> <li><em>Why it matters: Revealed the state space of DNA methylation</em></li> </ul> </li> <li> <p>Kriaucionis S, Heintz N. (2009) “The nuclear DNA base 5-hydroxymethylcytosine is present in Purkinje neurons and the brain.” <em>Science</em> 324(5929):929-30.</p> </li> <li>Koh KP, et al. (2011) “Tet1 and Tet2 regulate 5-hydroxymethylcytosine production and cell lineage specification in mouse embryonic stem cells.” <em>Cell Stem Cell</em> 8(2):200-13. <ul> <li><em>Why it matters: Showed 5hmC is abundant, not transient</em></li> </ul> </li> <li>Dawlaty MM, et al. (2011) “Tet1 is dispensable for maintaining pluripotency and its loss is compatible with embryonic and postnatal development.” <em>Cell Stem Cell</em> 9(2):166-75. <ul> <li><em>Why it matters: Network compensation in action</em></li> </ul> </li> <li> <p>Wu H, et al. (2011) “Genome-wide analysis of 5-hydroxymethylcytosine distribution reveals its dual function in transcriptional regulation in mouse embryonic stem cells.” <em>Genes Dev</em> 25(7):679-84.</p> </li> <li>Huang Y, et al. (2014) “Distinct roles of the methylcytosine oxidases Tet1 and Tet2 in mouse embryonic stem cells.” <em>PNAS</em> 111(4):1361-6.</li> </ol> <p><strong>On network thinking:</strong></p> <ol> <li>Alon U. (2007) “Network motifs: theory and experimental approaches.” <em>Nat Rev Genet</em> 8:450–461. <ul> <li><em>For when you want to formalize network thinking</em></li> </ul> </li> <li>Barabási AL, Oltvai ZN. (2004) “Network biology: understanding the cell’s functional organization.” <em>Nat Rev Genet</em> 5:101–113.</li> </ol> <p><strong>What I’m reading now:</strong></p> <ul> <li>Anything by Uri Alon on systems biology</li> <li>Papers on cellular plasticity and adaptive responses</li> <li>Multi-omics integration methods (still learning!)</li> </ul> <hr/> <p><em>This is part of my “Systems Biology for Biologists” series, where I’m documenting what I’m learning as I learn it. Mistakes, confusions, and all.</em></p> <p><em>If you’re also struggling with these concepts, let’s struggle together. Science is hard.</em></p>]]></content><author><name></name></author><category term="SciComm"/><category term="systems-biology"/><category term="computational-thinking"/><category term="epigenetics"/><category term="DNA-methylation"/><summary type="html"><![CDATA[Three years into my PhD, I finally understood what I was actually measuring. Here's what clicked.]]></summary></entry><entry><title type="html">Tracking Glioblastoma’s Circular DNA at Single-Cell Resolution</title><link href="https://ipekselcen.github.io/blog/2025/glioblastoma-ecdna/" rel="alternate" type="text/html" title="Tracking Glioblastoma’s Circular DNA at Single-Cell Resolution"/><published>2025-10-30T00:00:00+00:00</published><updated>2025-10-30T00:00:00+00:00</updated><id>https://ipekselcen.github.io/blog/2025/glioblastoma-ecdna</id><content type="html" xml:base="https://ipekselcen.github.io/blog/2025/glioblastoma-ecdna/"><![CDATA[<p>Glioblastoma is the most lethal brain cancer we know, with a median survival under two years even with aggressive treatment. One reason it’s so hard to treat is extrachromosomal DNA, which are circular DNA molecules that carry amplified oncogenes and exist outside the normal chromosomes.</p> <h2 id="the-ecdna-problem">The ecDNA Problem</h2> <p>Extrachromosomal DNA, or ecDNA, shows up in about 50-60% of glioblastomas, making it one of the most ecDNA-rich cancers. These circular DNA molecules typically carry oncogenes such as EGFR, PDGFRA, and CDK4, which are all drivers of aggressive tumor growth. What makes ecDNA particularly dangerous is how it behaves during cell division. Unlike chromosomal DNA, which gets precisely copied and distributed to daughter cells, ecDNA segregates randomly. One daughter cell might inherit many copies while another gets few or none, creating massive cell-to-cell variation in oncogene dosage. This heterogeneity fuels drug resistance and tumor evolution.</p> <p>The problem is that most ecDNA studies have relied on bulk sequencing or imaging approaches that average across thousands of cells, missing this critical heterogeneity. We’ve needed a way to track ecDNA at single-cell resolution in patient samples.</p> <h2 id="what-they-did">What They Did</h2> <p>A team from Soochow University developed scCirclehunter, a computational framework specifically designed to identify ecDNA from single-cell ATAC-seq data. The clever part is how they exploit chromatin accessibility patterns. EcDNA regions show distinctive accessibility signatures because they exist as circles rather than being packed into chromatin like chromosomal DNA. The method uses a pseudo-bulk strategy to first identify candidate ecDNA regions across all cells, then assigns these ecDNAs to specific cell populations using statistical modeling.</p> <p>They applied scCirclehunter to existing glioblastoma scATAC-seq datasets and showed it could reliably detect ecDNA and determine which individual cells carry it. This matters because it finally lets you ask: which tumor cells have ecDNA? How many copies? And what are those cells doing differently?</p> <h2 id="key-findings">Key Findings</h2> <p>The analysis revealed striking inter-patient and intra-tumor heterogeneity. Across different glioblastoma patients, ecDNA-carrying cells showed distinct distributions. Some patients had ecDNA throughout most of their tumor, while others showed more patchy distributions. Within a single patient harboring multiple different ecDNAs, they could track separate malignant cell trajectories associated with each ecDNA species. Focusing on ecNR2E1 (an ecDNA carrying the NR2E1 oncogene), they integrated the chromatin accessibility data with matched single-cell RNA-seq to understand how ecDNA affects cellular behavior. The ecDNA didn’t just amplify NR2E1 expression—it drove broader transcriptional programs associated with tumor aggressiveness. Cells carrying ecNR2E1 showed activation of pathways involved in cell proliferation, survival, and immune evasion. An unexpected finding emerged around mitochondrial dynamics. Cells with ecDNA showed evidence of increased mitochondrial transfer, which is a process where cells exchange mitochondria with neighbors. This suggests ecDNA-carrying cells might be manipulating their local environment in ways beyond just overexpressing oncogenes.</p> <h2 id="why-this-matters">Why This Matters</h2> <p>This work provides a generalizable approach for studying ecDNA heterogeneity in any cancer where scATAC-seq data exists. The single-cell resolution matters clinically because it reveals that ecDNA distribution isn’t uniform: some regions of a tumor might be ecDNA-heavy while others aren’t. This has implications for biopsy sampling, where a single needle biopsy might miss or oversample ecDNA-positive regions, and for understanding why tumors respond heterogeneously to treatment.</p> <p>From a therapeutic standpoint, knowing which cells carry ecDNA and what those cells are doing opens new targeting strategies. Rather than just going after the oncogene itself (such as EGFR inhibitors that often fail in ecDNA-positive tumors), you could potentially target the unique vulnerabilities of ecDNA-carrying cells or the mechanisms that maintain ecDNA.</p> <blockquote class="block-warning"> <h5 id="warning">WARNING</h5> <p>The broader point is methodological: chromatin accessibility data, which many researchers are already generating, contains information about structural genomic alterations like ecDNA that we haven’t been systematically extracting. scCirclehunter provides a way to mine existing datasets for insights into tumor heterogeneity that would otherwise remain hidden.</p> </blockquote> <blockquote class="block-tip"> <h5 id="tip">TIP</h5> <p><strong>Bottom Line:</strong> Glioblastoma’s circular DNA drives heterogeneity and treatment resistance, but we’ve lacked tools to track it cell-by-cell in patients. Single-cell chromatin accessibility provides a window into which cells carry ecDNA and how that shapes tumor behavior. As ecDNA-targeted therapies move toward the clinic, understanding its distribution at single-cell resolution will be critical for rational treatment design.</p> </blockquote> <table> <tbody> <tr> <td><strong>Paper:</strong> Jiang et al., <em>Cell Discovery</em> (2024)</td> <td><a href="https://www.nature.com/articles/s41421-025-00842-9">Read the paper →</a></td> </tr> </tbody> </table> <h3 id="references">References</h3> <ol> <li>Kim H, Nguyen NP, Turner K, et al. Extrachromosomal DNA is associated with oncogene amplification and poor outcome across multiple cancers. Nat Genet. 2020;52:891-897.</li> <li>Bailey C, Pich O, Thol K, et al. Origins and impact of extrachromosomal DNA. Nature. 2024;635:193-200.</li> <li>Lange JT, Rose JC, Chen CY, et al. The evolutionary dynamics of extrachromosomal DNA in human cancers. Nat Genet. 2022;54:1527-1533.</li> <li>Nathanson DA, Gini B, Mottahedeh J, et al. Targeted therapy resistance mediated by dynamic regulation of extrachromosomal mutant EGFR DNA. Science. 2014;343:72-76.</li> </ol>]]></content><author><name></name></author><category term="research-highlights"/><category term="circular"/><category term="DNA"/><category term="glioblastoma"/><category term="single-cell"/><category term="chromatin"/><summary type="html"><![CDATA[How single-cell epigenomics reveals that Alzheimer's is fundamentally about regulatory collapse, not just protein aggregates]]></summary></entry><entry><title type="html">Epigenomic Breakdown in Alzheimer’s: When Brain Cells Lose Control</title><link href="https://ipekselcen.github.io/blog/2025/alzheimers-epigenomics/" rel="alternate" type="text/html" title="Epigenomic Breakdown in Alzheimer’s: When Brain Cells Lose Control"/><published>2025-10-25T00:00:00+00:00</published><updated>2025-10-25T00:00:00+00:00</updated><id>https://ipekselcen.github.io/blog/2025/alzheimers-epigenomics</id><content type="html" xml:base="https://ipekselcen.github.io/blog/2025/alzheimers-epigenomics/"><![CDATA[<p>Most people think of Alzheimer’s disease in terms of plaques and tangles; the protein clumps that show up in brain scans. But a massive new study published in <em>Cell</em> this September reveals that the real story might be about something more fundamental: brain cells losing their grip on gene regulation itself.</p> <p>We’ve known for a while that Alzheimer’s doesn’t hit all brain regions equally. The hippocampus and entorhinal cortex (your memory centers) get hit early and hard, while other regions like the prefrontal cortex show damage later. But why? And at a cellular level, what’s actually breaking down?</p> <p>This is where single-cell epigenomics comes in. The epigenome (the chemical modifications that control which genes are accessible and which stay locked away) is essentially the instruction manual that tells each cell type how to be itself. When that manual gets corrupted, cells can’t maintain their identity or function properly. Single-cell technologies have revolutionized our ability to map cellular diversity and regulatory landscapes in the brain, but applying them to understand disease progression at this scale is still relatively new.</p> <h2 id="what-they-did">What They Did</h2> <p>The MIT and Broad Institute team, led by Manolis Kellis and Li-Huei Tsai, built the largest single-cell brain atlas for Alzheimer’s to date. They profiled 3.5 million individual cells from 384 postmortem brain samples spanning six different brain regions in 111 donors from the Religious Orders Study and Rush Memory and Aging Project (two well-characterized longitudinal cohort studies that have been instrumental in Alzheimer’s research).</p> <p>The donors ranged from people with no pathology to early-stage and late-stage disease. The key innovation is the integration of single-nucleus ATAC-seq (measuring chromatin accessibility) and single-nucleus RNA-seq (measuring gene expression) in the same tissue samples. This lets you see not just which genes are being expressed, but whether the regulatory machinery controlling those genes is intact or falling apart.</p> <h2 id="the-core-findings">The Core Findings</h2> <p>Two major patterns emerged that fundamentally change how we think about Alzheimer’s progression:</p> <p><strong>First: Epigenome relaxation and compartment breakdown.</strong> Healthy cells maintain strict spatial organization in their nuclei, with the genome partitioned into active and repressive compartments. Active compartments sit in the nuclear interior with accessible chromatin, while repressive compartments are near the nuclear periphery and lamina with higher A/T content.</p> <p>In Alzheimer’s, this organization breaks down. The cells experience what the authors call “epigenomic relaxation”: regions that should be tightly closed become accessible, and active regions lose their structure. Vulnerable neurons in the entorhinal cortex and hippocampus showed the most dramatic compartment switching, with normally repressive chromatin becoming inappropriately activated.</p> <p><strong>Second: Loss of epigenomic information.</strong> Each cell type has a unique epigenetic signature that defines what it is. In Alzheimer’s progression, cells lose this signature. They essentially forget how to be themselves. The study identified over 1 million candidate regulatory elements organized into 123 distinct modules across 67 cell subtypes, and tracked how these modules erode during disease.</p> <p>The loss was most pronounced in excitatory neurons in superficial cortical layers, somatostatin-positive inhibitory interneurons, oligodendrocytes, and microglia.</p> <p>Interestingly, glial cells showed a two-phase response. Early in disease, they gained epigenomic definition as they activated to respond to damage. But with sustained stress, they entered exhausted states and lost their epigenetic stability, especially pronounced in APOE4 carriers.</p> <h2 id="the-resilience-angle">The Resilience Angle</h2> <p>Here’s the hopeful part: some people maintained cognitive function despite having significant Alzheimer’s pathology in their brains. These “resilient” individuals showed something striking: their cells maintained higher epigenomic information across all brain regions compared to people who showed cognitive decline with similar pathology burdens. This suggests that preserving epigenetic stability might be protective, even when plaques and tangles are present.</p> <p>This study shifts the therapeutic conversation. Instead of just targeting plaques and tangles (the end products of disease) we could potentially target the regulatory factors that maintain epigenomic stability. The authors point to Polycomb complexes, which act as “epigenomic guardians” by maintaining chromatin structure. Strengthening these systems, or targeting the specific transcription factors that regulate vulnerable cell types, could offer new intervention strategies.</p> <p>The work complements a companion study published simultaneously in Cell, which found coordinated disruption of 3D genome organization alongside the epigenomic erosion described here. Together, these studies paint a comprehensive picture of how nuclear organization collapses in Alzheimer’s.</p> <p>The dataset itself is also a resource: all data is publicly available, giving the field a detailed molecular map of how different cell types in different brain regions respond to or resist Alzheimer’s pathology.</p> <h2 id="technical-notes">Technical Notes</h2> <p>The study used 10X Genomics platforms for both snATAC-seq (1.2 million nuclei) and snRNA-seq (2.3 million nuclei). They defined epigenomic compartments at genome-wide resolution using hidden Markov models, and calculated epigenomic information for single cells using Shannon entropy, quantifying how well cells maintain their cell-type-specific regulatory programs. Integration across regions and disease stages used Harmony for batch correction, with validation against ENCODE reference datasets.</p> <blockquote class="block-tip"> <h5 id="tip">TIP</h5> <p><strong>Bottom Line:</strong> Alzheimer’s isn’t just about protein aggregates. It’s about a progressive loss of the regulatory control that keeps brain cells functioning. Understanding epigenomic erosion opens new therapeutic avenues and helps explain why some people are resilient while others aren’t. This kind of comprehensive, multimodal atlas is exactly what the field needs to move beyond symptomatic treatments.</p> </blockquote> <table> <tbody> <tr> <td><strong>Paper:</strong> Liu et al., <em>Cell</em> (2025)</td> <td><a href="https://doi.org/10.1016/j.cell.2025.06.031">Read the paper →</a></td> </tr> </tbody> </table> <hr/> <h3 id="references">References</h3> <ul> <li>Kelsey G, Stegle O, Reik W. Single-cell epigenomics: Recording the past and predicting the future. <em>Science.</em> 2017;358(6359):69-75.</li> <li>Clark SJ, Lee HJ, Smallwood SA, Kelsey G, Reik W. Single-cell epigenomics: powerful new methods for understanding gene regulation and cell identity. <em>Genome Biol.</em> 2016;17:72.</li> <li>Bennett DA, Schneider JA, Arvanitakis Z, Wilson RS. Overview and findings from the religious orders study. <em>Curr Alzheimer Res.</em> 2012;9(6):628-645.</li> <li>Buenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. <em>Nat Methods.</em> 2013;10(12):1213-1218.</li> <li>Lieberman-Aiden E, van Berkum NL, Williams L, et al. Comprehensive mapping of long-range interactions reveals folding principles of the human genome. <em>Science.</em> 2009;326(5950):289-293.</li> <li>Dixon JR, Selvaraj S, Yue F, et al. Topological domains in mammalian genomes identified by analysis of chromatin interactions. <em>Nature.</em> 2012;485(7398):376-380.</li> <li>Arenaza-Urquijo EM, Vemuri P. Resistance vs resilience to Alzheimer disease: clarifying terminology for preclinical studies. <em>Neurology.</em> 2018;90(15):695-703.</li> <li>Mathys H, Boix CA, Akay LA, et al. Single-cell multiregion dissection of Alzheimer’s disease. <em>Nature.</em> 2024;632:858-868.</li> <li>Korsunsky I, Millard N, Fan J, et al. Fast, sensitive and accurate integration of single-cell data with Harmony. <em>Nat Methods.</em> 2019;16(12):1289-1296.</li> </ul>]]></content><author><name></name></author><category term="research-highlights"/><category term="epigenomics"/><category term="alzheimers"/><category term="single-cell"/><category term="chromatin"/><summary type="html"><![CDATA[How single-cell epigenomics reveals that Alzheimer's is fundamentally about regulatory collapse, not just protein aggregates]]></summary></entry></feed>