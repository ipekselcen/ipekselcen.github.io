<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ipekselcen.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ipekselcen.github.io/" rel="alternate" type="text/html"/><updated>2026-01-26T19:12:41+00:00</updated><id>https://ipekselcen.github.io/feed.xml</id><title type="html">blank</title><subtitle>Recent PhD graduate in Biochemistry specializing in epigenetics, chromatin biology, and multi-omics analysis. Bridging wet lab expertise with computational approaches. </subtitle><entry><title type="html">The Method That Taught Biologists to Code (Without Knowing It)</title><link href="https://ipekselcen.github.io/blog/2026/bisulfite/" rel="alternate" type="text/html" title="The Method That Taught Biologists to Code (Without Knowing It)"/><published>2026-01-17T00:00:00+00:00</published><updated>2026-01-17T00:00:00+00:00</updated><id>https://ipekselcen.github.io/blog/2026/bisulfite</id><content type="html" xml:base="https://ipekselcen.github.io/blog/2026/bisulfite/"><![CDATA[<blockquote> <p><strong>For the biologist who learned to code out of necessity:</strong> This post traces how three experimental breakthroughs in epigenetics inadvertently taught us computational thinking—before we even knew we were learning it.</p> </blockquote> <h2 id="the-problem-that-changed-everything">The Problem That Changed Everything</h2> <p><strong>1992, UC San Francisco.</strong> Marianne Frommer faced what seemed like an impossible question: how do you tell the difference between a methylated cytosine and an unmethylated one?</p> <p>Both are cytosines. Both look identical under a microscope. Both have the same mass on a spectrometer. The only difference—one has a methyl group (-CH₃), the other doesn’t—is chemically silent in most assays.</p> <p>Her solution seemed almost comically simple: treat DNA with sodium bisulfite. Under harsh conditions (high temperature, low pH, hours of incubation), something remarkable happens. Unmethylated cytosines convert to uracils. Methylated cytosines stay cytosines, as the methyl group protects them.</p> <p>Sequence the treated DNA, and you get your answer. Except you don’t get a direct readout of methylation. You get sequences full of Ts (converted from unmethylated Cs) and Cs (that stayed methylated because they were protected). Someone, or something, has to infer the original methylation state by comparing treated to untreated DNA.</p> <blockquote> <p><strong>The moment Frommer created bisulfite sequencing, she created a computational problem.</strong></p> </blockquote> <p>That inference step? That’s <strong>decomposition</strong>—the first principle of computational thinking. Breaking down a complex biological question (“What’s methylated?”) into a series of logical steps that must be executed in order.</p> <hr/> <h2 id="what-bisulfite-sequencing-actually-forced-you-to-do">What Bisulfite Sequencing Actually Forced You to Do</h2> <p>Let’s unpack what running bisulfite sequencing required in those early days. This is computational thinking emerging in real time:</p> <p><strong>The experimental question:</strong> “What is the methylation status of my genomic region?”</p> <p><strong>The computational breakdown:</strong></p> <ol> <li>Sequence both bisulfite-treated and untreated DNA</li> <li>Align bisulfite-converted reads to a reference genome (but the reads don’t match perfectly anymore because C→T conversions make them different)</li> <li>For every cytosine in the reference, ask: did it stay C (methylated) or become T (unmethylated)?</li> <li>Calculate methylation percentage per site across multiple reads</li> <li>Account for incomplete conversion (some Cs don’t convert even if unmethylated—your bisulfite kit isn’t perfect)</li> <li>Account for sequencing errors (some Ts might be sequencing mistakes, not conversions)</li> </ol> <p><strong>Each of these is its own computational problem.</strong> And here’s what’s fascinating: in the 1990s and early 2000s, biologists did steps 3-6 <em>by hand</em>, often using Excel. They were doing computational thinking without formal training. They just called it “analyzing my data.”</p> <blockquote> <h5 id="editorial-note-what-made-this-a-methods-paper">Editorial Note: What Made This a Methods Paper</h5> <p>Frommer et al. (1992) in <em>PNAS</em> is a masterclass in methods innovation. The paper:</p> <ul> <li><strong>Identified a chemical property</strong> (differential deamination) that could encode biological information</li> <li><strong>Validated the method</strong> on known methylated sites (CG islands)</li> <li><strong>Demonstrated generalizability</strong> across different genomic contexts</li> <li><strong>Acknowledged limitations</strong> (incomplete conversion, sequencing requirements)</li> </ul> </blockquote> <p><strong>Why this matters for Nature Methods readers:</strong> The best methods papers don’t just describe a new technique. They show how the technique enables questions that were previously unanswerable. Frommer’s innovation wasn’t just measuring methylation—it was measuring methylation <em>at single-nucleotide resolution</em>.</p> <p>The computational burden this created? That was a feature, not a bug. It forced the field to develop tools that would become essential for all sequencing-based methods.</p> <p class="block-tip"><strong>Reference:</strong> Frommer, M. et al. (1992). “A genomic sequencing protocol that yields a positive display of 5-methylcytosine residues in individual DNA strands.” <em>PNAS</em> 89(5):1827-1831.</p> <h2 id="the-pattern-recognition-breakthrough-atac-seqs-hidden-data">The Pattern Recognition Breakthrough: ATAC-seq’s Hidden Data</h2> <p>Fast forward to 2013. Jason Buenrostro, a graduate student in Bill Greenleaf’s lab at Stanford, developed ATAC-seq (Assay for Transposase-Accessible Chromatin using sequencing).</p> <p>The experimental approach is elegantly simple: a hyperactive transposase (Tn5) simultaneously cuts DNA at accessible regions and inserts sequencing adapters. No crosslinking, no sonication, no antibodies. Just Tn5, some cells, and a sequencer.</p> <p>Sequence the fragments. Count where they came from. You have a map of open chromatin.</p> <p><strong>Except that’s not all you have.</strong></p> <h3 id="the-data-everyone-ignored-at-first">The Data Everyone Ignored (At First)</h3> <p>Here’s what early ATAC-seq papers did:</p> <ol> <li>Align reads to the genome</li> <li>Call peaks where reads pile up</li> <li>Conclude: “This region is accessible”</li> <li>Discard everything else</li> </ol> <p>But “everything else” included fragment length. And fragment length turned out to encode an enormous amount of information that was sitting there all along.</p> <p>Think about what Tn5 actually does: it cuts accessible DNA. But DNA isn’t naked—it’s wrapped around nucleosomes. Tn5 cuts in the linker regions between nucleosomes, or in nucleosome-free regions at regulatory elements.</p> <ul> <li><strong>Fragments ~40-50 bp:</strong> Tn5 cut on both sides of a transcription factor or other protein. Nucleosome-free region.</li> <li><strong>Fragments ~200 bp:</strong> Tn5 cut in flanking linkers around one nucleosome. Mononucleosome.</li> <li><strong>Fragments ~400 bp:</strong> Two nucleosomes with linker. Dinucleosome.</li> </ul> <p><strong>This is pattern recognition:</strong> seeing signal in what everyone else thought was noise.</p> <blockquote> <h5 id="editorial-note-when-simple-gets-sophisticated">Editorial Note: When Simple Gets Sophisticated</h5> <p>Buenrostro et al. (2013) in <em>Nature Methods</em> appeared straightforward: replace DNase-seq’s complex protocol with Tn5 tagmentation. But the method’s real innovation emerged later, as the field recognized patterns in the data.</p> </blockquote> <p><strong>Evolution of ATAC-seq analysis:</strong></p> <ul> <li><strong>2013:</strong> Peak calling only</li> <li><strong>2015:</strong> Fragment length distributions reveal nucleosome positioning</li> <li><strong>2016:</strong> NucleoATAC extracts transcription factor footprints</li> <li><strong>2019:</strong> Single-cell ATAC-seq with droplet microfluidics</li> <li><strong>2023:</strong> Paired-tag methods for chromatin + RNA in same cells</li> </ul> <p><strong>What this teaches about methods evaluation:</strong> The best methods create data that the developers didn’t fully know how to interpret yet. ATAC-seq’s fragment lengths were always there. It took the field 2-3 years to systematically recognize the patterns.</p> <p><strong>When reviewing methods papers, ask:</strong> Is the data richer than the analysis shown? Are there unexploited features that could enable future discoveries?</p> <p class="block-tip"><strong>Reference:</strong> Buenrostro, J.D. et al. (2013). “Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position.” <em>Nature Methods</em> 10:1213–1218.</p> <h2 id="algorithmic-thinking-the-peak-calling-problem">Algorithmic Thinking: The Peak Calling Problem</h2> <p>Let me tell you about the first time I ran ChIP-seq analysis during my PhD.</p> <p>I had beautiful peaks. Gorgeous enrichment. Except when I looked closer, I also had peaks in:</p> <ul> <li>Telomeres (my transcription factor doesn’t bind there)</li> <li>Mitochondrial DNA (contamination)</li> <li>Highly repetitive regions (alignment artifacts)</li> <li>Random background noise that just happened to be slightly higher than average</li> </ul> <p>The naive approach—”count reads in windows, call high regions as peaks”—gave me garbage. I needed an algorithm that understood the structure of the problem.</p> <h3 id="how-chip-seq-taught-me-algorithmic-thinking">How ChIP-seq Taught Me Algorithmic Thinking</h3> <p><strong>ChIP-seq gives you:</strong> Millions of DNA fragments representing where your protein of interest was bound.</p> <p><strong>Your challenge:</strong> Where, <em>exactly</em>, were the binding sites?</p> <p>This is algorithmic thinking: designing a step-by-step procedure that accounts for how your data was actually generated.</p> <table> <thead> <tr> <th>❌ <strong>Naive Algorithm (What I Tried First)</strong></th> <th>✅ <strong>Sophisticated Algorithm (MACS2)</strong></th> </tr> </thead> <tbody> <tr> <td>1. Align reads to genome</td> <td>1. Model local background using control samples</td> </tr> <tr> <td>2. Count reads in sliding windows</td> <td>2. Shift reads to estimate fragment centers</td> </tr> <tr> <td>3. Call regions with high counts as “peaks”</td> <td>3. Use dynamic lambda (local background varies!)</td> </tr> <tr> <td>4. Get overwhelmed by false positives</td> <td>4. Calculate fold enrichment AND statistical significance</td> </tr> <tr> <td>5. Spend weeks troubleshooting</td> <td>5. Call peaks using FDR cutoff</td> </tr> <tr> <td> </td> <td>6. Report peak summits, not just regions</td> </tr> </tbody> </table> <p>The difference? MACS2 doesn’t just count. It <strong>models the data generation process</strong>: how reads are created from fragments, how background varies locally, how sequencing depth affects power. Then it uses that model to make better inferences.</p> <p>This is the essence of algorithmic thinking: understanding <em>why</em> the data looks the way it does, then designing procedures that account for that structure.</p> <blockquote> <h5 id="editorial-note-the-importance-of-thoughtful-defaults">Editorial Note: The Importance of Thoughtful Defaults</h5> <p>Zhang et al. (2008) developed MACS specifically to address ChIP-seq’s systematic biases. What makes it a landmark methods paper:</p> </blockquote> <p><strong>Problem definition:</strong> ChIP-seq enrichment isn’t uniform. Background varies by:</p> <ul> <li>Local GC content</li> <li>Mappability</li> <li>Open chromatin state</li> <li>Sequencing depth artifacts</li> </ul> <p><strong>Algorithmic innovation:</strong> Dynamic local lambda calculation. Instead of one global background threshold, MACS estimates expected background in windows around each potential peak.</p> <p><strong>Impact:</strong> MACS became the field standard not just because it worked well, but because its defaults worked well. Most users never tuned parameters—the algorithm was designed around realistic assumptions about ChIP-seq data.</p> <p><strong>For methods developers:</strong> Good defaults are not laziness. They’re a service to users who don’t have the time or statistical background to optimize every parameter. Your algorithm should work out-of-the-box for 80% of use cases.</p> <p class="block-tip"><strong>Reference:</strong> Zhang, Y. et al. (2008). “Model-based analysis of ChIP-Seq (MACS).” <em>Genome Biology</em> 9:R137.</p> <h2 id="the-computational-thinking-you-already-had">The Computational Thinking You Already Had</h2> <p>Here’s what I realized during my PhD, somewhere around year 4 when I was knee-deep in hMeRIP-seq analysis and trying to figure out why my peaks didn’t make biological sense:</p> <p><strong>I was already thinking computationally. I just didn’t call it that.</strong></p> <p>When I troubleshot why my Western blot didn’t work, I was doing <strong>decomposition</strong>: breaking down the protocol into steps, testing each one systematically, identifying where the failure occurred.</p> <p>When I noticed my ChIP peaks always appeared near transcription start sites and wondered if that was biological signal or technical artifact, I was doing <strong>pattern recognition</strong>: seeing structure in data and asking what it meant.</p> <p>When I wrote detailed protocols for CRISPR cloning that could work for any guide RNA, I was doing <strong>abstraction</strong>: designing procedures that generalize beyond specific examples.</p> <p>The transition to computational biology wasn’t learning to think differently. It was learning to apply problem-solving skills I already had to questions where the “experiment” was running code instead of pipetting samples.</p> <hr/> <h2 id="what-this-means-for-reading-methods-papers">What This Means for Reading Methods Papers</h2> <p>Next time you read a methods paper—especially if you’re evaluating it for significance, rigor, or publication—ask yourself:</p> <p><strong>Decomposition:</strong></p> <ul> <li>What is the experimental readout, and what biological question does it answer?</li> <li>What computational steps are required to go from raw data to biological conclusion?</li> <li>Are any of these steps new/challenging/rate-limiting for the field?</li> </ul> <p><strong>Pattern recognition:</strong></p> <ul> <li>What patterns in the data indicate signal vs. noise?</li> <li>Are there features being exploited that weren’t obvious at first (like ATAC fragment lengths)?</li> <li>What assumptions about data structure does the analysis make?</li> </ul> <p><strong>Algorithmic thinking:</strong></p> <ul> <li>Could you explain the analysis procedure to someone and they’d get the same results?</li> <li>How does the algorithm handle edge cases (low coverage, ambiguous mappings, batch effects)?</li> <li>Are the defaults reasonable? Would naive users get good results out-of-the-box?</li> </ul> <p>These questions aren’t just academic. They’re how you evaluate whether a method is truly innovative or just incrementally different from what already exists.</p> <hr/> <h2 id="looking-ahead">Looking Ahead</h2> <p>Three methods. Three computational thinking lessons:</p> <table> <thead> <tr> <th>Method</th> <th>Year</th> <th>Computational Skill Taught</th> </tr> </thead> <tbody> <tr> <td><strong>Bisulfite sequencing</strong></td> <td>1992</td> <td>Decomposition—inference from transformed data</td> </tr> <tr> <td><strong>ATAC-seq</strong></td> <td>2013</td> <td>Pattern recognition—signal in fragment lengths</td> </tr> <tr> <td><strong>ChIP-seq peak calling</strong></td> <td>2008</td> <td>Algorithmic thinking—modeling data generation</td> </tr> </tbody> </table> <p>But here’s what’s interesting: we’ve only covered methods that work on <em>one data type</em> at a time. What happens when methods from different fields start talking to each other?</p> <p>What happens when you want to measure chromatin accessibility AND gene expression AND DNA methylation in the <em>same cells</em>?</p> <p>That’s where we’re going in Part 2: the multi-omics revolution, and the computational thinking skill that made it possible—<strong>abstraction</strong>.</p> <hr/> <h2 id="references">References</h2> <p><strong>Historical methods:</strong></p> <ul> <li> <p>Frommer, M. et al. (1992). “A genomic sequencing protocol that yields a positive display of 5-methylcytosine residues in individual DNA strands.” <em>PNAS</em> 89(5):1827-1831. <a href="https://pubmed.ncbi.nlm.nih.gov/1542678/">PubMed</a></p> </li> <li> <p>Buenrostro, J.D. et al. (2013). “Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position.” <em>Nature Methods</em> 10:1213–1218. <a href="https://pubmed.ncbi.nlm.nih.gov/24097267/">PubMed</a></p> </li> </ul> <p><strong>Computational tools:</strong></p> <ul> <li> <p>Zhang, Y. et al. (2008). “Model-based analysis of ChIP-Seq (MACS).” <em>Genome Biology</em> 9:R137. <a href="https://pubmed.ncbi.nlm.nih.gov/18798982/">PubMed</a></p> </li> <li> <p>Schep, A.N. et al. (2017). “chromVAR: inferring transcription-factor-associated accessibility from single-cell epigenomic data.” <em>Nature Methods</em> 14:975–978. <a href="https://pubmed.ncbi.nlm.nih.gov/28825706/">PubMed</a></p> </li> <li> <p>Schep, A.N. et al. (2015). “Structured nucleosome fingerprints enable high-resolution mapping of chromatin architecture within regulatory regions.” <em>Genome Research</em> 25:1757-1770. <a href="https://pubmed.ncbi.nlm.nih.gov/26314830/">PubMed</a> (NucleoATAC)</p> </li> </ul> <hr/> <p><strong>Next in this series:</strong> <em>Part 2: When Chromatin Methods Converged—The Multi-Omics Revolution</em></p> <hr/> <p><em>This is Part 1 of a 3-part series on computational thinking for chromatin biologists. Written by a chromatin biologist who learned computational thinking the hard way—by running experiments that generated data I didn’t know how to analyze.</em></p>]]></content><author><name></name></author><category term="research-highlights"/><category term="epigenetics,"/><category term="computational-thinking,"/><category term="methods,"/><category term="DNA-methylation,"/><category term="chromatin"/><summary type="html"><![CDATA[For the biologist who learned to code out of necessity: This post traces how three experimental breakthroughs in epigenetics inadvertently taught us computational thinking—before we even knew we were learning it.]]></summary></entry><entry><title type="html">What I Wish Someone Had Told Me About TET1: A Computational Thinking Journey</title><link href="https://ipekselcen.github.io/blog/2026/tet1-computational-thinking/" rel="alternate" type="text/html" title="What I Wish Someone Had Told Me About TET1: A Computational Thinking Journey"/><published>2026-01-02T00:00:00+00:00</published><updated>2026-01-02T00:00:00+00:00</updated><id>https://ipekselcen.github.io/blog/2026/tet1-computational-thinking</id><content type="html" xml:base="https://ipekselcen.github.io/blog/2026/tet1-computational-thinking/"><![CDATA[<p>I spent the first two years of my PhD memorizing pathways. “TET1 oxidizes 5-methylcytosine.” Check. “5hmC is an intermediate in demethylation.” Check. “TET enzymes regulate gene expression.” Check.</p> <p>Then I knocked out TET2 in my oligodendrocyte progenitor cells, ran RNA-seq, and… nothing made sense.</p> <p>The patterns I saw didn’t match any textbook. My PI was confused. I was confused. I’d generated beautiful data but had no framework to interpret it. That’s when I realized: <strong>I’d been memorizing recipes without understanding the logic</strong>.</p> <p>This post is what I wish someone had told me in year one. Not as a computational expert - I’m still learning - but as someone who finally started asking different questions.</p> <h2 id="the-problem-with-how-we-learn-biology">The Problem With How We Learn Biology</h2> <p>Here’s how I was taught DNA methylation:</p> <blockquote class="block-warning"> <p><strong>The Clean Story</strong></p> <ul> <li>DNA gets methylated (5mC) → Gene silenced</li> <li>DNA loses methylation → Gene active</li> <li>TET enzymes reverse methylation</li> <li>Therefore: TET knockout = more methylation = more silencing</li> </ul> </blockquote> <p>This made perfect sense in lectures. It completely failed in my experiments.</p> <p><strong>Why?</strong> Because biology isn’t a linear pathway. It’s a network with:</p> <ul> <li><strong>Redundancy</strong> (TET1, TET2, AND TET3 - why three?)</li> <li><strong>Compensation</strong> (lose one, others adapt)</li> <li><strong>Context-dependence</strong> (same enzyme, different outcomes in different cells)</li> <li><strong>Multi-layer regulation</strong> (not just DNA methylation - chromatin, RNA modifications, metabolic state)</li> </ul> <p>Nobody told me this. I had to learn it by banging my head against confusing data for months.</p> <h2 id="the-turning-point-tet1-discovery">The Turning Point: TET1 Discovery</h2> <p>In 2009, TET1 was discovered.<sup>1</sup> The textbook version goes:</p> <p>“TET1 oxidizes 5-methylcytosine, providing a mechanism for active DNA demethylation.”</p> <p><strong>What I missed</strong> (and what took me years to appreciate): This wasn’t just finding a new enzyme. It was revealing that <strong>DNA methylation is a state space, not a binary switch</strong>.</p> <h3 id="what-that-actually-means">What That Actually Means</h3> <p>Instead of:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Methylated (OFF) ⟷ Unmethylated (ON)
</code></pre></div></div> <p>We have:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>C → 5mC → 5hmC → 5fC → 5caC → C
</code></pre></div></div> <p><strong>Why does this matter?</strong> Because each state:</p> <ul> <li>Has different protein readers</li> <li>Exists at different stability levels</li> <li>Serves different regulatory functions</li> <li>Creates different biological outcomes</li> </ul> <p>This means the cell can encode way more information than just “on” or “off.” It can create states like:</p> <ul> <li>“Poised” (ready to activate quickly)</li> <li>“Active but dynamic” (fluctuating)</li> <li>“Progressively shutting down” (transitioning)</li> <li>“Stably repressed” (locked)</li> </ul> <blockquote class="block-tip"> <p><strong>What Clicked For Me</strong></p> <p>When I first learned about 5hmC, I thought: “Oh, an intermediate. Cool.”</p> <p>What I should have thought: “Wait - if 5hmC accumulates to 1% of all cytosines in ESCs, it’s NOT just an intermediate. It’s serving a function. The cell is CHOOSING to keep DNA in this intermediate state.”</p> <p>That shift - from thinking about intermediates to thinking about <strong>states the cell maintains</strong> - changed everything.</p> </blockquote> <h2 id="my-tet2-confusion-and-what-it-taught-me">My TET2 Confusion (And What It Taught Me)</h2> <p>Let me tell you about my actual data, because this is where linear thinking completely broke down.</p> <p><strong>My prediction (linear thinking):</strong></p> <ul> <li>TET2 knockout → less 5hmC → more stable 5mC → genes stay repressed</li> </ul> <p><strong>What I actually saw:</strong></p> <ul> <li>TET2 knockout → some 5hmC decrease BUT</li> <li>TET1 and TET3 expression increased (compensation)</li> <li>RNA modifications changed (unexpected)</li> <li>Chromatin accessibility shifted at unexpected sites</li> <li>Gene expression changes didn’t correlate simply with 5hmC loss</li> </ul> <p><strong>My PI’s reaction:</strong> “This is messy. Maybe technical variation?”</p> <p><strong>What was actually happening:</strong> The cell was adapting. Network compensation. Multi-layer regulation. <strong>Exactly what you’d predict if you thought computationally</strong>, but I didn’t have that framework yet.</p> <h2 id="what-thinking-computationally-actually-means">What “Thinking Computationally” Actually Means</h2> <p>I used to think “computational biology” meant “learning Python and running pipelines.”</p> <p>That’s not it.</p> <p><strong>Computational thinking means asking:</strong></p> <ol> <li><strong>What’s the state space?</strong> (Not just “on/off” - what are ALL possible states?)</li> <li><strong>What are the network connections?</strong> (Who compensates when something breaks?)</li> <li><strong>What are the multi-layer regulations?</strong> (DNA methylation doesn’t act alone)</li> <li><strong>What’s the cell optimizing for?</strong> (Stability vs. flexibility? Speed vs. accuracy?)</li> </ol> <p>Let me show you what this looks like in practice.</p> <h3 id="question-1-why-three-tet-enzymes">Question 1: Why Three TET Enzymes?</h3> <p><strong>Linear thinking:</strong> “Evolution is messy. Probably redundant.”</p> <p><strong>Computational thinking:</strong> “Redundancy in biology usually means something. Let me think about this as a network.”</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This is how I started thinking about it
# (Warning: I'm still learning Python, this is conceptual)
</span>
<span class="n">network</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">TET1</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">targets</span><span class="sh">'</span><span class="p">:</span> <span class="n">gene_set</span><span class="p">,</span> <span class="sh">'</span><span class="s">expression</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">constitutive</span><span class="sh">'</span><span class="p">},</span>
    <span class="sh">'</span><span class="s">TET2</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">targets</span><span class="sh">'</span><span class="p">:</span> <span class="n">gene_set</span><span class="p">,</span> <span class="sh">'</span><span class="s">expression</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">inducible</span><span class="sh">'</span><span class="p">},</span>  
    <span class="sh">'</span><span class="s">TET3</span><span class="sh">'</span><span class="p">:</span> <span class="p">{</span><span class="sh">'</span><span class="s">targets</span><span class="sh">'</span><span class="p">:</span> <span class="n">gene_set</span><span class="p">,</span> <span class="sh">'</span><span class="s">expression</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">tissue_specific</span><span class="sh">'</span><span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Question: If I knock out TET2, what happens?
# Linear: TET2 targets lose 5hmC
# Network: Do TET1/3 compensate? Do cells reroute regulation?
</span></code></pre></div></div> <p>When I finally looked at published TET1 knockout data,<sup>4</sup> mice were <strong>viable and fertile</strong>. Subtle defects, but mostly fine.</p> <p><strong>Why?</strong> Network compensation. TET2 and TET3 picked up the slack.</p> <p><strong>What this taught me:</strong> When you see three enzymes doing similar things, don’t think “redundant waste.” Think “robust system with failsafes.”</p> <p>The cell isn’t stupid. We’re just not asking the right questions.</p> <h3 id="question-2-is-5hmc-transient-or-stable">Question 2: Is 5hmC Transient or Stable?</h3> <p>This is where computational thinking saved me from misinterpreting my own data.</p> <p><strong>What I measured:</strong> 5hmC at certain promoters in my OPCs.</p> <p><strong>Linear interpretation:</strong> “5hmC is present, so demethylation is happening here.”</p> <p><strong>Computational question:</strong> “Wait - if 5hmC is just a transient intermediate, why is it so abundant in ESCs (1% of all cytosines)?”<sup>3</sup></p> <p>Let me think about kinetics:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># If 5hmC is transient:</span><span class="w">
</span><span class="c1"># k1 (5mC → 5hmC) ≈ k2 (5hmC → 5fC)</span><span class="w">
</span><span class="c1"># Steady state: [5hmC] should be very low</span><span class="w">

</span><span class="c1"># If 5hmC is stable:</span><span class="w">
</span><span class="c1"># k1 (5mC → 5hmC) &gt;&gt; k2 (5hmC → 5fC)  </span><span class="w">
</span><span class="c1"># Steady state: [5hmC] accumulates</span><span class="w">

</span><span class="c1"># The data shows: 5hmC is ABUNDANT</span><span class="w">
</span><span class="c1"># Therefore: k2 must be slow</span><span class="w">
</span><span class="c1"># Meaning: 5hmC is not just passing through</span><span class="w">
</span></code></pre></div></div> <p><strong>What this means:</strong> 5hmC isn’t just “on the way to demethylation.” It’s a <strong>mark the cell maintains</strong> to keep genes in a poised state.</p> <p><strong>Why this matters for my research:</strong> When I see 5hmC at a promoter in my OPCs, it might not mean “actively demethylating.” It might mean “maintaining plasticity” - ready to go either way depending on signals.</p> <p>Completely different biological interpretation. Same data.</p> <blockquote class="block-warning"> <p><strong>The Struggle Is Real</strong></p> <p>I didn’t figure this out quickly. I spent MONTHS confused about my 5hmC data. I kept thinking “is my hMeRIP-seq bad?” when really, I was asking the wrong questions.</p> <p>The turning point was reading papers about 5hmC in development and realizing: <strong>the cell uses 5hmC to maintain flexible states</strong>. It’s not a bug, it’s a feature.</p> </blockquote> <h2 id="the-multi-layer-reality-nobody-tells-you">The Multi-Layer Reality Nobody Tells You</h2> <p>Here’s what really frustrated me: <strong>Every paper I read would focus on ONE layer of regulation</strong> and claim causality.</p> <p>“TET2 mutation causes reduced 5hmC, leading to gene X downregulation.”</p> <p>But when I looked at my data, I had to ask:</p> <ul> <li>Did chromatin accessibility change? (Yes)</li> <li>Did RNA modifications change? (Yes, unexpectedly)</li> <li>Did metabolic state shift? (Probably)</li> <li>Did other TET enzymes compensate? (Definitely)</li> <li>Were there feedback loops I’m missing? (Almost certainly)</li> </ul> <p><strong>The reality:</strong> DNA methylation is ONE layer in a multi-layer regulatory system.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cell State
    ↓
Metabolic State → ATP levels → Chromatin Remodeling
    ↓                              ↓
Transcription Factors → Chromatin Accessibility
    ↓                              ↓
DNA Methylation (5mC/5hmC) ← RNA Modifications
    ↓                              ↓
Histone Modifications → Gene Expression
    ↓
Feedback Loops
</code></pre></div></div> <p><strong>When you perturb ONE thing</strong> (like knocking out TET2), the <strong>entire system responds</strong>. You’re not seeing “the effect of TET2” - you’re seeing the <strong>system’s adaptation to losing TET2</strong>.</p> <p>This is why:</p> <ul> <li>My RNA-seq alone didn’t tell the story</li> <li>I needed ATAC-seq to see chromatin changes</li> <li>I needed hMeRIP-seq to see RNA modification responses</li> <li>I needed metabolic profiling to understand the cellular state</li> <li>I STILL don’t have the complete picture</li> </ul> <h2 id="what-i-do-differently-now">What I Do Differently Now</h2> <p>I’m not going to pretend I have this figured out. I’m still learning. But here’s what changed in how I approach my research:</p> <h3 id="before-running-experiments">Before Running Experiments</h3> <p><strong>Old me:</strong> “I’ll knock out TET2 and do RNA-seq.”</p> <p><strong>Current me:</strong></p> <ol> <li>Draw the network on paper. Where are backup systems?</li> <li>What multi-layer regulations exist?</li> <li>What would linear thinking predict?</li> <li>What would network compensation predict?</li> <li>What additional data would I need to distinguish these?</li> </ol> <p><strong>This doesn’t mean I always do the perfect experiment.</strong> Money and time are real constraints. But at least I <strong>know what I’m missing</strong>.</p> <h3 id="when-analyzing-data">When Analyzing Data</h3> <p><strong>Old me:</strong> Run DESeq2 → Get gene list → Run GO enrichment → Call it a day</p> <p><strong>Current me:</strong></p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># After DESeq2, ask:</span><span class="w">
</span><span class="c1"># 1. Does this pattern match network predictions?</span><span class="w">
</span><span class="c1"># 2. Are compensatory genes changing?</span><span class="w">
</span><span class="c1"># 3. What if I'm measuring adaptation, not direct effects?</span><span class="w">
</span><span class="c1"># 4. What other layers should I check?</span><span class="w">

</span><span class="c1"># Example from my actual analysis:</span><span class="w">
</span><span class="n">results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">DESeq2_results</span><span class="w">
</span><span class="n">up_genes</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">filter</span><span class="p">(</span><span class="n">results</span><span class="p">,</span><span class="w"> </span><span class="n">log2FC</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">padj</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">0.05</span><span class="p">)</span><span class="w">

</span><span class="c1"># Check: Are TET1/TET3 in my up-regulated genes?</span><span class="w">
</span><span class="c1"># If yes → network compensation, as predicted</span><span class="w">
</span><span class="c1"># If no → something else is going on, investigate</span><span class="w">
</span></code></pre></div></div> <h3 id="when-reading-papers">When Reading Papers</h3> <p><strong>Old me:</strong> Trust the interpretation in the abstract.</p> <p><strong>Current me:</strong></p> <ul> <li>Did they check for compensation?</li> <li>Is this correlation or causation?</li> <li>What layers of regulation did they ignore?</li> <li>Would their conclusions hold if the system adapted?</li> </ul> <p><strong>Example:</strong> I recently read a paper claiming “TET2 loss causes specific gene downregulation.”</p> <p>Red flags:</p> <ul> <li>❌ Didn’t measure TET1/TET3 (compensation?)</li> <li>❌ Didn’t measure chromatin state (accessibility changes?)</li> <li>❌ Endpoint analysis only (what about dynamics?)</li> <li>❌ Assumed direct causality (network effects?)</li> </ul> <p>I’m not saying the paper is wrong. I’m saying <strong>their interpretation assumed linearity</strong> in a clearly non-linear system.</p> <h2 id="the-checklist-i-use-now">The Checklist I Use Now</h2> <p>Before making claims about my data, I ask:</p> <p><strong>□ State Space Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Am I thinking binary when I should think spectrum?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What states can the system occupy?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What transitions are possible?</li> </ul> <p><strong>□ Network Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What compensates if this breaks?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Are there parallel pathways?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What feedback loops exist?</li> </ul> <p><strong>□ Multi-Layer Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What other regulatory layers are involved?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Did I measure them?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>If not, how does that limit my interpretation?</li> </ul> <p><strong>□ Plasticity Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Is the cell adapting to my perturbation?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Am I measuring steady-state or transition?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Would temporal dynamics change my interpretation?</li> </ul> <p><strong>□ Causality Questions</strong></p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Am I claiming correlation or causation?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What experiment would actually test causality?</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>What would change my conclusion?</li> </ul> <blockquote class="block-tip"> <p><strong>Reality Check</strong></p> <p>Do I do all of this perfectly? No.</p> <p>Do I have time and money to measure every layer? No.</p> <p>But at least I <strong>know what I’m not measuring</strong> and can qualify my claims accordingly.</p> <p>That’s the difference.</p> </blockquote> <h2 id="what-im-still-learning">What I’m Still Learning</h2> <p>Let me be honest about where I struggle:</p> <p><strong>1. When to stop adding complexity</strong></p> <p>I can spiral into “but what about…” forever. Sometimes you need to make simplifying assumptions to make progress. I’m still learning where to draw that line.</p> <p><strong>2. Quantitative predictions</strong></p> <p>I can think about networks qualitatively. Making actual quantitative predictions? That’s harder. I’m working on it.</p> <p><strong>3. Integrating all the data</strong></p> <p>I have RNA-seq, ATAC-seq, hMeRIP-seq sitting on my hard drive. Integrating them properly is… a work in progress. The conceptual framework is there. The practical execution is messy.</p> <p><strong>4. Communicating uncertainty</strong></p> <p>In talks, PIs want definitive statements. “TET2 regulates gene X.” But what I actually mean is: “TET2 loss correlates with gene X changes, possibly through network adaptation involving chromatin and RNA modifications, but I haven’t proven causality.”</p> <p>How do you say that in a conference talk without sounding wishy-washy?</p> <p>Still figuring that out.</p> <h2 id="why-this-matters-for-you">Why This Matters For You</h2> <p>If you’re early in your PhD (or considering grad school), <strong>please learn this framework earlier than I did</strong>.</p> <p>Not because it makes research easier - it doesn’t. If anything, it makes you realize how much you DON’T know.</p> <p>But it will save you from:</p> <ul> <li>❌ Making overclaimed conclusions</li> <li>❌ Being confused when knockouts don’t match predictions</li> <li>❌ Missing compensation mechanisms</li> <li>❌ Thinking your “messy” data is bad when it’s actually informative</li> </ul> <p><strong>Biology is not linear.</strong> Cells are plastic, adaptive, multi-layer regulatory systems.</p> <p><strong>The sooner you think that way, the better.</strong></p> <h2 id="whats-next">What’s Next</h2> <p>I’m working on a companion post about chromatin accessibility using the same framework - thinking about it as a probability landscape rather than “open” vs “closed.”</p> <p>I’m also writing up my TET2 work (finally). The compensation mechanisms we found are… not what textbooks would predict. But they make perfect sense when you think computationally.</p> <p>After publication, I’ll write about what we learned and what I still don’t understand.</p> <p>For now, if you’re struggling with confusing epigenetics data, know that:</p> <ol> <li>You’re not alone</li> <li>Your data probably isn’t bad</li> <li>You might just be asking linear questions about a non-linear system</li> </ol> <p>Start thinking about networks, plasticity, and multi-layer regulation. Your confusion might turn into clarity.</p> <p>At least, that’s what happened for me.</p> <blockquote class="block-tip"> <p><strong>Coming Up</strong></p> <ul> <li>“Chromatin Accessibility as Probability: What Your ATAC-seq Really Measures”</li> <li>“The TET2 Story: When Compensation Mechanisms Surprise You” (after publication)</li> <li>“How I Actually Analyze Multi-Omics Data (Messy Reality Edition)”</li> </ul> </blockquote> <hr/> <h3 id="references--further-reading">References &amp; Further Reading</h3> <p><strong>The papers that changed how I think:</strong></p> <ol> <li>Tahiliani M, et al. (2009) “Conversion of 5-methylcytosine to 5-hydroxymethylcytosine in mammalian DNA by MLL partner TET1.” <em>Science</em> 324(5929):930-5. <ul> <li><em>Why it matters: Revealed the state space of DNA methylation</em></li> </ul> </li> <li> <p>Kriaucionis S, Heintz N. (2009) “The nuclear DNA base 5-hydroxymethylcytosine is present in Purkinje neurons and the brain.” <em>Science</em> 324(5929):929-30.</p> </li> <li>Koh KP, et al. (2011) “Tet1 and Tet2 regulate 5-hydroxymethylcytosine production and cell lineage specification in mouse embryonic stem cells.” <em>Cell Stem Cell</em> 8(2):200-13. <ul> <li><em>Why it matters: Showed 5hmC is abundant, not transient</em></li> </ul> </li> <li>Dawlaty MM, et al. (2011) “Tet1 is dispensable for maintaining pluripotency and its loss is compatible with embryonic and postnatal development.” <em>Cell Stem Cell</em> 9(2):166-75. <ul> <li><em>Why it matters: Network compensation in action</em></li> </ul> </li> <li> <p>Wu H, et al. (2011) “Genome-wide analysis of 5-hydroxymethylcytosine distribution reveals its dual function in transcriptional regulation in mouse embryonic stem cells.” <em>Genes Dev</em> 25(7):679-84.</p> </li> <li>Huang Y, et al. (2014) “Distinct roles of the methylcytosine oxidases Tet1 and Tet2 in mouse embryonic stem cells.” <em>PNAS</em> 111(4):1361-6.</li> </ol> <p><strong>On network thinking:</strong></p> <ol> <li>Alon U. (2007) “Network motifs: theory and experimental approaches.” <em>Nat Rev Genet</em> 8:450–461. <ul> <li><em>For when you want to formalize network thinking</em></li> </ul> </li> <li>Barabási AL, Oltvai ZN. (2004) “Network biology: understanding the cell’s functional organization.” <em>Nat Rev Genet</em> 5:101–113.</li> </ol> <p><strong>What I’m reading now:</strong></p> <ul> <li>Anything by Uri Alon on systems biology</li> <li>Papers on cellular plasticity and adaptive responses</li> <li>Multi-omics integration methods (still learning!)</li> </ul> <hr/> <p><em>This is part of my “Systems Biology for Biologists” series, where I’m documenting what I’m learning as I learn it. Mistakes, confusions, and all.</em></p> <p><em>If you’re also struggling with these concepts, let’s struggle together. Science is hard.</em></p>]]></content><author><name></name></author><category term="SciComm"/><category term="systems-biology"/><category term="computational-thinking"/><category term="epigenetics"/><category term="DNA-methylation"/><summary type="html"><![CDATA[Three years into my PhD, I finally understood what I was actually measuring. Here's what clicked.]]></summary></entry><entry><title type="html">Tracking Glioblastoma’s Circular DNA at Single-Cell Resolution</title><link href="https://ipekselcen.github.io/blog/2025/glioblastoma-ecdna/" rel="alternate" type="text/html" title="Tracking Glioblastoma’s Circular DNA at Single-Cell Resolution"/><published>2025-10-30T00:00:00+00:00</published><updated>2025-10-30T00:00:00+00:00</updated><id>https://ipekselcen.github.io/blog/2025/glioblastoma-ecdna</id><content type="html" xml:base="https://ipekselcen.github.io/blog/2025/glioblastoma-ecdna/"><![CDATA[<p>Glioblastoma is the most lethal brain cancer we know, with a median survival under two years even with aggressive treatment. One reason it’s so hard to treat is extrachromosomal DNA, which are circular DNA molecules that carry amplified oncogenes and exist outside the normal chromosomes.</p> <h2 id="the-ecdna-problem">The ecDNA Problem</h2> <p>Extrachromosomal DNA, or ecDNA, shows up in about 50-60% of glioblastomas, making it one of the most ecDNA-rich cancers. These circular DNA molecules typically carry oncogenes such as EGFR, PDGFRA, and CDK4, which are all drivers of aggressive tumor growth. What makes ecDNA particularly dangerous is how it behaves during cell division. Unlike chromosomal DNA, which gets precisely copied and distributed to daughter cells, ecDNA segregates randomly. One daughter cell might inherit many copies while another gets few or none, creating massive cell-to-cell variation in oncogene dosage. This heterogeneity fuels drug resistance and tumor evolution.</p> <p>The problem is that most ecDNA studies have relied on bulk sequencing or imaging approaches that average across thousands of cells, missing this critical heterogeneity. We’ve needed a way to track ecDNA at single-cell resolution in patient samples.</p> <h2 id="what-they-did">What They Did</h2> <p>A team from Soochow University developed scCirclehunter, a computational framework specifically designed to identify ecDNA from single-cell ATAC-seq data. The clever part is how they exploit chromatin accessibility patterns. EcDNA regions show distinctive accessibility signatures because they exist as circles rather than being packed into chromatin like chromosomal DNA. The method uses a pseudo-bulk strategy to first identify candidate ecDNA regions across all cells, then assigns these ecDNAs to specific cell populations using statistical modeling.</p> <p>They applied scCirclehunter to existing glioblastoma scATAC-seq datasets and showed it could reliably detect ecDNA and determine which individual cells carry it. This matters because it finally lets you ask: which tumor cells have ecDNA? How many copies? And what are those cells doing differently?</p> <h2 id="key-findings">Key Findings</h2> <p>The analysis revealed striking inter-patient and intra-tumor heterogeneity. Across different glioblastoma patients, ecDNA-carrying cells showed distinct distributions. Some patients had ecDNA throughout most of their tumor, while others showed more patchy distributions. Within a single patient harboring multiple different ecDNAs, they could track separate malignant cell trajectories associated with each ecDNA species. Focusing on ecNR2E1 (an ecDNA carrying the NR2E1 oncogene), they integrated the chromatin accessibility data with matched single-cell RNA-seq to understand how ecDNA affects cellular behavior. The ecDNA didn’t just amplify NR2E1 expression—it drove broader transcriptional programs associated with tumor aggressiveness. Cells carrying ecNR2E1 showed activation of pathways involved in cell proliferation, survival, and immune evasion. An unexpected finding emerged around mitochondrial dynamics. Cells with ecDNA showed evidence of increased mitochondrial transfer, which is a process where cells exchange mitochondria with neighbors. This suggests ecDNA-carrying cells might be manipulating their local environment in ways beyond just overexpressing oncogenes.</p> <h2 id="why-this-matters">Why This Matters</h2> <p>This work provides a generalizable approach for studying ecDNA heterogeneity in any cancer where scATAC-seq data exists. The single-cell resolution matters clinically because it reveals that ecDNA distribution isn’t uniform: some regions of a tumor might be ecDNA-heavy while others aren’t. This has implications for biopsy sampling, where a single needle biopsy might miss or oversample ecDNA-positive regions, and for understanding why tumors respond heterogeneously to treatment.</p> <p>From a therapeutic standpoint, knowing which cells carry ecDNA and what those cells are doing opens new targeting strategies. Rather than just going after the oncogene itself (such as EGFR inhibitors that often fail in ecDNA-positive tumors), you could potentially target the unique vulnerabilities of ecDNA-carrying cells or the mechanisms that maintain ecDNA.</p> <blockquote class="block-warning"> <h5 id="warning">WARNING</h5> <p>The broader point is methodological: chromatin accessibility data, which many researchers are already generating, contains information about structural genomic alterations like ecDNA that we haven’t been systematically extracting. scCirclehunter provides a way to mine existing datasets for insights into tumor heterogeneity that would otherwise remain hidden.</p> </blockquote> <blockquote class="block-tip"> <h5 id="tip">TIP</h5> <p><strong>Bottom Line:</strong> Glioblastoma’s circular DNA drives heterogeneity and treatment resistance, but we’ve lacked tools to track it cell-by-cell in patients. Single-cell chromatin accessibility provides a window into which cells carry ecDNA and how that shapes tumor behavior. As ecDNA-targeted therapies move toward the clinic, understanding its distribution at single-cell resolution will be critical for rational treatment design.</p> </blockquote> <table> <tbody> <tr> <td><strong>Paper:</strong> Jiang et al., <em>Cell Discovery</em> (2024)</td> <td><a href="https://www.nature.com/articles/s41421-025-00842-9">Read the paper →</a></td> </tr> </tbody> </table> <h3 id="references">References</h3> <ol> <li>Kim H, Nguyen NP, Turner K, et al. Extrachromosomal DNA is associated with oncogene amplification and poor outcome across multiple cancers. Nat Genet. 2020;52:891-897.</li> <li>Bailey C, Pich O, Thol K, et al. Origins and impact of extrachromosomal DNA. Nature. 2024;635:193-200.</li> <li>Lange JT, Rose JC, Chen CY, et al. The evolutionary dynamics of extrachromosomal DNA in human cancers. Nat Genet. 2022;54:1527-1533.</li> <li>Nathanson DA, Gini B, Mottahedeh J, et al. Targeted therapy resistance mediated by dynamic regulation of extrachromosomal mutant EGFR DNA. Science. 2014;343:72-76.</li> </ol>]]></content><author><name></name></author><category term="research-highlights"/><category term="circular"/><category term="DNA"/><category term="glioblastoma"/><category term="single-cell"/><category term="chromatin"/><summary type="html"><![CDATA[How single-cell epigenomics reveals that Alzheimer's is fundamentally about regulatory collapse, not just protein aggregates]]></summary></entry><entry><title type="html">Epigenomic Breakdown in Alzheimer’s: When Brain Cells Lose Control</title><link href="https://ipekselcen.github.io/blog/2025/alzheimers-epigenomics/" rel="alternate" type="text/html" title="Epigenomic Breakdown in Alzheimer’s: When Brain Cells Lose Control"/><published>2025-10-25T00:00:00+00:00</published><updated>2025-10-25T00:00:00+00:00</updated><id>https://ipekselcen.github.io/blog/2025/alzheimers-epigenomics</id><content type="html" xml:base="https://ipekselcen.github.io/blog/2025/alzheimers-epigenomics/"><![CDATA[<p>Most people think of Alzheimer’s disease in terms of plaques and tangles; the protein clumps that show up in brain scans. But a massive new study published in <em>Cell</em> this September reveals that the real story might be about something more fundamental: brain cells losing their grip on gene regulation itself.</p> <p>We’ve known for a while that Alzheimer’s doesn’t hit all brain regions equally. The hippocampus and entorhinal cortex (your memory centers) get hit early and hard, while other regions like the prefrontal cortex show damage later. But why? And at a cellular level, what’s actually breaking down?</p> <p>This is where single-cell epigenomics comes in. The epigenome (the chemical modifications that control which genes are accessible and which stay locked away) is essentially the instruction manual that tells each cell type how to be itself. When that manual gets corrupted, cells can’t maintain their identity or function properly. Single-cell technologies have revolutionized our ability to map cellular diversity and regulatory landscapes in the brain, but applying them to understand disease progression at this scale is still relatively new.</p> <h2 id="what-they-did">What They Did</h2> <p>The MIT and Broad Institute team, led by Manolis Kellis and Li-Huei Tsai, built the largest single-cell brain atlas for Alzheimer’s to date. They profiled 3.5 million individual cells from 384 postmortem brain samples spanning six different brain regions in 111 donors from the Religious Orders Study and Rush Memory and Aging Project (two well-characterized longitudinal cohort studies that have been instrumental in Alzheimer’s research).</p> <p>The donors ranged from people with no pathology to early-stage and late-stage disease. The key innovation is the integration of single-nucleus ATAC-seq (measuring chromatin accessibility) and single-nucleus RNA-seq (measuring gene expression) in the same tissue samples. This lets you see not just which genes are being expressed, but whether the regulatory machinery controlling those genes is intact or falling apart.</p> <h2 id="the-core-findings">The Core Findings</h2> <p>Two major patterns emerged that fundamentally change how we think about Alzheimer’s progression:</p> <p><strong>First: Epigenome relaxation and compartment breakdown.</strong> Healthy cells maintain strict spatial organization in their nuclei, with the genome partitioned into active and repressive compartments. Active compartments sit in the nuclear interior with accessible chromatin, while repressive compartments are near the nuclear periphery and lamina with higher A/T content.</p> <p>In Alzheimer’s, this organization breaks down. The cells experience what the authors call “epigenomic relaxation”: regions that should be tightly closed become accessible, and active regions lose their structure. Vulnerable neurons in the entorhinal cortex and hippocampus showed the most dramatic compartment switching, with normally repressive chromatin becoming inappropriately activated.</p> <p><strong>Second: Loss of epigenomic information.</strong> Each cell type has a unique epigenetic signature that defines what it is. In Alzheimer’s progression, cells lose this signature. They essentially forget how to be themselves. The study identified over 1 million candidate regulatory elements organized into 123 distinct modules across 67 cell subtypes, and tracked how these modules erode during disease.</p> <p>The loss was most pronounced in excitatory neurons in superficial cortical layers, somatostatin-positive inhibitory interneurons, oligodendrocytes, and microglia.</p> <p>Interestingly, glial cells showed a two-phase response. Early in disease, they gained epigenomic definition as they activated to respond to damage. But with sustained stress, they entered exhausted states and lost their epigenetic stability, especially pronounced in APOE4 carriers.</p> <h2 id="the-resilience-angle">The Resilience Angle</h2> <p>Here’s the hopeful part: some people maintained cognitive function despite having significant Alzheimer’s pathology in their brains. These “resilient” individuals showed something striking: their cells maintained higher epigenomic information across all brain regions compared to people who showed cognitive decline with similar pathology burdens. This suggests that preserving epigenetic stability might be protective, even when plaques and tangles are present.</p> <p>This study shifts the therapeutic conversation. Instead of just targeting plaques and tangles (the end products of disease) we could potentially target the regulatory factors that maintain epigenomic stability. The authors point to Polycomb complexes, which act as “epigenomic guardians” by maintaining chromatin structure. Strengthening these systems, or targeting the specific transcription factors that regulate vulnerable cell types, could offer new intervention strategies.</p> <p>The work complements a companion study published simultaneously in Cell, which found coordinated disruption of 3D genome organization alongside the epigenomic erosion described here. Together, these studies paint a comprehensive picture of how nuclear organization collapses in Alzheimer’s.</p> <p>The dataset itself is also a resource: all data is publicly available, giving the field a detailed molecular map of how different cell types in different brain regions respond to or resist Alzheimer’s pathology.</p> <h2 id="technical-notes">Technical Notes</h2> <p>The study used 10X Genomics platforms for both snATAC-seq (1.2 million nuclei) and snRNA-seq (2.3 million nuclei). They defined epigenomic compartments at genome-wide resolution using hidden Markov models, and calculated epigenomic information for single cells using Shannon entropy, quantifying how well cells maintain their cell-type-specific regulatory programs. Integration across regions and disease stages used Harmony for batch correction, with validation against ENCODE reference datasets.</p> <blockquote class="block-tip"> <h5 id="tip">TIP</h5> <p><strong>Bottom Line:</strong> Alzheimer’s isn’t just about protein aggregates. It’s about a progressive loss of the regulatory control that keeps brain cells functioning. Understanding epigenomic erosion opens new therapeutic avenues and helps explain why some people are resilient while others aren’t. This kind of comprehensive, multimodal atlas is exactly what the field needs to move beyond symptomatic treatments.</p> </blockquote> <table> <tbody> <tr> <td><strong>Paper:</strong> Liu et al., <em>Cell</em> (2025)</td> <td><a href="https://doi.org/10.1016/j.cell.2025.06.031">Read the paper →</a></td> </tr> </tbody> </table> <hr/> <h3 id="references">References</h3> <ul> <li>Kelsey G, Stegle O, Reik W. Single-cell epigenomics: Recording the past and predicting the future. <em>Science.</em> 2017;358(6359):69-75.</li> <li>Clark SJ, Lee HJ, Smallwood SA, Kelsey G, Reik W. Single-cell epigenomics: powerful new methods for understanding gene regulation and cell identity. <em>Genome Biol.</em> 2016;17:72.</li> <li>Bennett DA, Schneider JA, Arvanitakis Z, Wilson RS. Overview and findings from the religious orders study. <em>Curr Alzheimer Res.</em> 2012;9(6):628-645.</li> <li>Buenrostro JD, Giresi PG, Zaba LC, Chang HY, Greenleaf WJ. Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. <em>Nat Methods.</em> 2013;10(12):1213-1218.</li> <li>Lieberman-Aiden E, van Berkum NL, Williams L, et al. Comprehensive mapping of long-range interactions reveals folding principles of the human genome. <em>Science.</em> 2009;326(5950):289-293.</li> <li>Dixon JR, Selvaraj S, Yue F, et al. Topological domains in mammalian genomes identified by analysis of chromatin interactions. <em>Nature.</em> 2012;485(7398):376-380.</li> <li>Arenaza-Urquijo EM, Vemuri P. Resistance vs resilience to Alzheimer disease: clarifying terminology for preclinical studies. <em>Neurology.</em> 2018;90(15):695-703.</li> <li>Mathys H, Boix CA, Akay LA, et al. Single-cell multiregion dissection of Alzheimer’s disease. <em>Nature.</em> 2024;632:858-868.</li> <li>Korsunsky I, Millard N, Fan J, et al. Fast, sensitive and accurate integration of single-cell data with Harmony. <em>Nat Methods.</em> 2019;16(12):1289-1296.</li> </ul>]]></content><author><name></name></author><category term="research-highlights"/><category term="epigenomics"/><category term="alzheimers"/><category term="single-cell"/><category term="chromatin"/><summary type="html"><![CDATA[How single-cell epigenomics reveals that Alzheimer's is fundamentally about regulatory collapse, not just protein aggregates]]></summary></entry></feed>